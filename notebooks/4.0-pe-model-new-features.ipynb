{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import  pyplot as plt\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"../data/interim/003-raw-clean-data.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import (RandomForestRegressor,\n",
    "                              AdaBoostRegressor,\n",
    "                              GradientBoostingRegressor,\n",
    "                              ExtraTreesRegressor\n",
    "                              )\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.svm import SVR,LinearSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "def tuner(clf,x,y,params,cv_fold=5,n_iter = 10):\n",
    "    cv = model_selection.RandomizedSearchCV(estimator=clf,param_distributions=params,n_iter=n_iter,scoring={\"r2\" : metrics.make_scorer(metrics.r2_score),\"mse\" : \"neg_mean_squared_error\"},cv=cv_fold,verbose=2,return_train_score=True,refit=\"r2\")\n",
    "    cv.fit(x,y)\n",
    "    return cv\n",
    "\n",
    "def benchmark(clf,X_train,y_train,X_test,y_test,params,feature_names=None,**kwargs):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(str(clf).split('(')[0])\n",
    "    t0 = time()\n",
    "\n",
    "    cv_res = tuner(clf,X_train,y_train,params=params,n_iter=kwargs.get('n_iter',10),cv_fold=kwargs.get('cv_fold',5))\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    y_pred = cv_res.best_estimator_.predict(X_test)\n",
    "    r2 = metrics.r2_score(y_test, y_pred)\n",
    "    mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "    mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "    print(\"r2:\",r2)\n",
    "    print(\"Mean Absolute Error :\",mae)\n",
    "    print(\"Mean Sq Error :\",mse)    \n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "        if feature_names is not None:\n",
    "            importance = cv_res.best_estimator_.coef_\n",
    "            x = np.argsort(importance)[-20:]\n",
    "            plt.bar(range(0,len(x)),importance[x])\n",
    "            plt.xticks(range(0,len(x)),tuple(feature_names[x]),rotation='vertical')\n",
    "            plt.show()\n",
    "            print(\"top 10 keywords per class:\")            \n",
    "            print(\" \".join(feature_names[x]))\n",
    "        print()\n",
    "    elif hasattr(clf,'feature_importances_'):\n",
    "        if feature_names is not None:\n",
    "            importance = cv_res.best_estimator_.feature_importances_\n",
    "            x = np.argsort(importance)[-20:]\n",
    "            plt.bar(range(0,len(x)),importance[x])\n",
    "            plt.xticks(range(0,len(x)),tuple(feature_names[x]),rotation='vertical')\n",
    "            plt.show()\n",
    "            print(\"top 10 keywords per class:\")            \n",
    "            print(\" \".join(feature_names[x]))\n",
    "        print()\n",
    "    \n",
    "    print()\n",
    "    return cv_res.best_estimator_,pd.DataFrame(cv_res.cv_results_),mse,mae,r2, train_time, test_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_cont = ['location','measurement_depth_cm', 'measurement_height_cm',\n",
    "       'measurement_width_cm', 'material', 'day', 'month', 'week', 'year',\n",
    "       'surface', 'is_artist_dead', 'aspect_ratio', 'years_sold']\n",
    "dummy = ['location','material']\n",
    "\n",
    "X = pd.get_dummies(data[pred_cont],columns=dummy)\n",
    "lbl = data[\"hammer_price\"]\n",
    "train,test,y_train,y_test = model_selection.train_test_split(X,lbl,train_size=0.7,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "StackingCVRegressor\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[CV] meta-randomforestregressor__n_estimators=500, meta-randomforestregressor__max_features=0.7 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   34.9s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  meta-randomforestregressor__n_estimators=500, meta-randomforestregressor__max_features=0.7, total=  54.4s\n",
      "[CV] meta-randomforestregressor__n_estimators=500, meta-randomforestregressor__max_features=0.7 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   35.2s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   40.2s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  meta-randomforestregressor__n_estimators=500, meta-randomforestregressor__max_features=0.7, total= 1.0min\n",
      "[CV] meta-randomforestregressor__n_estimators=500, meta-randomforestregressor__max_features=0.7 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   34.5s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   39.5s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  meta-randomforestregressor__n_estimators=500, meta-randomforestregressor__max_features=0.7, total= 1.0min\n",
      "[CV] meta-randomforestregressor__n_estimators=50, meta-randomforestregressor__max_features=0.5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  meta-randomforestregressor__n_estimators=50, meta-randomforestregressor__max_features=0.5, total=  21.3s\n",
      "[CV] meta-randomforestregressor__n_estimators=50, meta-randomforestregressor__max_features=0.5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  meta-randomforestregressor__n_estimators=50, meta-randomforestregressor__max_features=0.5, total=  21.5s\n",
      "[CV] meta-randomforestregressor__n_estimators=50, meta-randomforestregressor__max_features=0.5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  5.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  meta-randomforestregressor__n_estimators=50, meta-randomforestregressor__max_features=0.5, total=  22.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 357.707s\n",
      "r2: 0.104863110407\n",
      "Mean Absolute Error : 126425.996559\n",
      "Mean Sq Error : 566165515779.0\n",
      "test time:  5.500s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.regressor import StackingCVRegressor\n",
    "rf = RandomForestRegressor(n_jobs=-1,verbose=1)\n",
    "stack = StackingCVRegressor(\n",
    "    regressors=(        \n",
    "        KNeighborsRegressor(n_neighbors=3),\n",
    "        KNeighborsRegressor(n_neighbors=7),\n",
    "        KNeighborsRegressor(n_neighbors=5),\n",
    "        SGDRegressor(loss='epsilon_insensitive',alpha=0.1),\n",
    "        SGDRegressor(loss='epsilon_insensitive',alpha=0.0001 ),\n",
    "        SGDRegressor(loss='epsilon_insensitive',alpha = 100)\n",
    "    ),meta_regressor=rf,use_features_in_secondary=False,store_train_meta_features=True)\n",
    "\n",
    "param_grid={            \n",
    "        'meta-randomforestregressor__n_estimators': [10,50,100,500],\n",
    "        'meta-randomforestregressor__max_features' : [3,5,0.3,0.5,0.7]\n",
    "    }\n",
    "\n",
    "res = benchmark(stack,train.values,y_train.values,test.values,y_test.values,param_grid,np.array(train.columns),n_iter=2,cv_fold=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "GradientBoostingRegressor\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV] n_estimators=30, min_samples_leaf=150, max_features=0.3, max_depth=4, learning_rate=0.01 \n",
      "[CV]  n_estimators=30, min_samples_leaf=150, max_features=0.3, max_depth=4, learning_rate=0.01, total=   1.5s\n",
      "[CV] n_estimators=30, min_samples_leaf=150, max_features=0.3, max_depth=4, learning_rate=0.01 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=30, min_samples_leaf=150, max_features=0.3, max_depth=4, learning_rate=0.01, total=   1.5s\n",
      "[CV] n_estimators=30, min_samples_leaf=150, max_features=0.3, max_depth=4, learning_rate=0.01 \n",
      "[CV]  n_estimators=30, min_samples_leaf=150, max_features=0.3, max_depth=4, learning_rate=0.01, total=   1.5s\n",
      "[CV] n_estimators=30, min_samples_leaf=150, max_features=0.3, max_depth=4, learning_rate=0.01 \n",
      "[CV]  n_estimators=30, min_samples_leaf=150, max_features=0.3, max_depth=4, learning_rate=0.01, total=   1.4s\n",
      "[CV] n_estimators=30, min_samples_leaf=150, max_features=0.3, max_depth=4, learning_rate=0.01 \n",
      "[CV]  n_estimators=30, min_samples_leaf=150, max_features=0.3, max_depth=4, learning_rate=0.01, total=   1.4s\n",
      "[CV] n_estimators=70, min_samples_leaf=20, max_features=0.3, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=70, min_samples_leaf=20, max_features=0.3, max_depth=6, learning_rate=0.02, total=   6.7s\n",
      "[CV] n_estimators=70, min_samples_leaf=20, max_features=0.3, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=70, min_samples_leaf=20, max_features=0.3, max_depth=6, learning_rate=0.02, total=   6.8s\n",
      "[CV] n_estimators=70, min_samples_leaf=20, max_features=0.3, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=70, min_samples_leaf=20, max_features=0.3, max_depth=6, learning_rate=0.02, total=   6.9s\n",
      "[CV] n_estimators=70, min_samples_leaf=20, max_features=0.3, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=70, min_samples_leaf=20, max_features=0.3, max_depth=6, learning_rate=0.02, total=   6.6s\n",
      "[CV] n_estimators=70, min_samples_leaf=20, max_features=0.3, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=70, min_samples_leaf=20, max_features=0.3, max_depth=6, learning_rate=0.02, total=   6.5s\n",
      "[CV] n_estimators=60, min_samples_leaf=100, max_features=0.1, max_depth=8, learning_rate=0.05 \n",
      "[CV]  n_estimators=60, min_samples_leaf=100, max_features=0.1, max_depth=8, learning_rate=0.05, total=   3.2s\n",
      "[CV] n_estimators=60, min_samples_leaf=100, max_features=0.1, max_depth=8, learning_rate=0.05 \n",
      "[CV]  n_estimators=60, min_samples_leaf=100, max_features=0.1, max_depth=8, learning_rate=0.05, total=   3.2s\n",
      "[CV] n_estimators=60, min_samples_leaf=100, max_features=0.1, max_depth=8, learning_rate=0.05 \n",
      "[CV]  n_estimators=60, min_samples_leaf=100, max_features=0.1, max_depth=8, learning_rate=0.05, total=   3.3s\n",
      "[CV] n_estimators=60, min_samples_leaf=100, max_features=0.1, max_depth=8, learning_rate=0.05 \n",
      "[CV]  n_estimators=60, min_samples_leaf=100, max_features=0.1, max_depth=8, learning_rate=0.05, total=   3.4s\n",
      "[CV] n_estimators=60, min_samples_leaf=100, max_features=0.1, max_depth=8, learning_rate=0.05 \n",
      "[CV]  n_estimators=60, min_samples_leaf=100, max_features=0.1, max_depth=8, learning_rate=0.05, total=   3.4s\n",
      "[CV] n_estimators=20, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=20, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.05, total=   0.9s\n",
      "[CV] n_estimators=20, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=20, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.05, total=   0.9s\n",
      "[CV] n_estimators=20, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=20, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.05, total=   0.8s\n",
      "[CV] n_estimators=20, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=20, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.05, total=   0.9s\n",
      "[CV] n_estimators=20, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=20, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.05, total=   0.8s\n",
      "[CV] n_estimators=60, min_samples_leaf=20, max_features=1.0, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=60, min_samples_leaf=20, max_features=1.0, max_depth=6, learning_rate=0.02, total=  16.0s\n",
      "[CV] n_estimators=60, min_samples_leaf=20, max_features=1.0, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=60, min_samples_leaf=20, max_features=1.0, max_depth=6, learning_rate=0.02, total=  15.5s\n",
      "[CV] n_estimators=60, min_samples_leaf=20, max_features=1.0, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=60, min_samples_leaf=20, max_features=1.0, max_depth=6, learning_rate=0.02, total=  16.0s\n",
      "[CV] n_estimators=60, min_samples_leaf=20, max_features=1.0, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=60, min_samples_leaf=20, max_features=1.0, max_depth=6, learning_rate=0.02, total=  15.3s\n",
      "[CV] n_estimators=60, min_samples_leaf=20, max_features=1.0, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=60, min_samples_leaf=20, max_features=1.0, max_depth=6, learning_rate=0.02, total=  15.3s\n",
      "[CV] n_estimators=20, min_samples_leaf=50, max_features=0.3, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=20, min_samples_leaf=50, max_features=0.3, max_depth=6, learning_rate=0.05, total=   2.0s\n",
      "[CV] n_estimators=20, min_samples_leaf=50, max_features=0.3, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=20, min_samples_leaf=50, max_features=0.3, max_depth=6, learning_rate=0.05, total=   2.0s\n",
      "[CV] n_estimators=20, min_samples_leaf=50, max_features=0.3, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=20, min_samples_leaf=50, max_features=0.3, max_depth=6, learning_rate=0.05, total=   2.0s\n",
      "[CV] n_estimators=20, min_samples_leaf=50, max_features=0.3, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=20, min_samples_leaf=50, max_features=0.3, max_depth=6, learning_rate=0.05, total=   2.0s\n",
      "[CV] n_estimators=20, min_samples_leaf=50, max_features=0.3, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=20, min_samples_leaf=50, max_features=0.3, max_depth=6, learning_rate=0.05, total=   2.0s\n",
      "[CV] n_estimators=50, min_samples_leaf=20, max_features=0.3, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=50, min_samples_leaf=20, max_features=0.3, max_depth=8, learning_rate=0.1, total=   7.8s\n",
      "[CV] n_estimators=50, min_samples_leaf=20, max_features=0.3, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=50, min_samples_leaf=20, max_features=0.3, max_depth=8, learning_rate=0.1, total=   7.8s\n",
      "[CV] n_estimators=50, min_samples_leaf=20, max_features=0.3, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=50, min_samples_leaf=20, max_features=0.3, max_depth=8, learning_rate=0.1, total=   7.9s\n",
      "[CV] n_estimators=50, min_samples_leaf=20, max_features=0.3, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=50, min_samples_leaf=20, max_features=0.3, max_depth=8, learning_rate=0.1, total=   8.0s\n",
      "[CV] n_estimators=50, min_samples_leaf=20, max_features=0.3, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=50, min_samples_leaf=20, max_features=0.3, max_depth=8, learning_rate=0.1, total=   7.8s\n",
      "[CV] n_estimators=60, min_samples_leaf=150, max_features=1.0, max_depth=6, learning_rate=0.01 \n",
      "[CV]  n_estimators=60, min_samples_leaf=150, max_features=1.0, max_depth=6, learning_rate=0.01, total=  15.1s\n",
      "[CV] n_estimators=60, min_samples_leaf=150, max_features=1.0, max_depth=6, learning_rate=0.01 \n",
      "[CV]  n_estimators=60, min_samples_leaf=150, max_features=1.0, max_depth=6, learning_rate=0.01, total=  15.2s\n",
      "[CV] n_estimators=60, min_samples_leaf=150, max_features=1.0, max_depth=6, learning_rate=0.01 \n",
      "[CV]  n_estimators=60, min_samples_leaf=150, max_features=1.0, max_depth=6, learning_rate=0.01, total=  15.8s\n",
      "[CV] n_estimators=60, min_samples_leaf=150, max_features=1.0, max_depth=6, learning_rate=0.01 \n",
      "[CV]  n_estimators=60, min_samples_leaf=150, max_features=1.0, max_depth=6, learning_rate=0.01, total=  15.7s\n",
      "[CV] n_estimators=60, min_samples_leaf=150, max_features=1.0, max_depth=6, learning_rate=0.01 \n",
      "[CV]  n_estimators=60, min_samples_leaf=150, max_features=1.0, max_depth=6, learning_rate=0.01, total=  16.1s\n",
      "[CV] n_estimators=30, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=30, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05, total=   1.2s\n",
      "[CV] n_estimators=30, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=30, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05, total=   1.2s\n",
      "[CV] n_estimators=30, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=30, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05, total=   1.2s\n",
      "[CV] n_estimators=30, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=30, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05, total=   1.2s\n",
      "[CV] n_estimators=30, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=30, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05, total=   1.1s\n",
      "[CV] n_estimators=60, min_samples_leaf=50, max_features=1.0, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=60, min_samples_leaf=50, max_features=1.0, max_depth=6, learning_rate=0.02, total=  16.4s\n",
      "[CV] n_estimators=60, min_samples_leaf=50, max_features=1.0, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=60, min_samples_leaf=50, max_features=1.0, max_depth=6, learning_rate=0.02, total=  16.2s\n",
      "[CV] n_estimators=60, min_samples_leaf=50, max_features=1.0, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=60, min_samples_leaf=50, max_features=1.0, max_depth=6, learning_rate=0.02, total=  17.0s\n",
      "[CV] n_estimators=60, min_samples_leaf=50, max_features=1.0, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=60, min_samples_leaf=50, max_features=1.0, max_depth=6, learning_rate=0.02, total=  15.6s\n",
      "[CV] n_estimators=60, min_samples_leaf=50, max_features=1.0, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=60, min_samples_leaf=50, max_features=1.0, max_depth=6, learning_rate=0.02, total=  16.6s\n",
      "[CV] n_estimators=50, min_samples_leaf=100, max_features=0.3, max_depth=4, learning_rate=0.05 \n",
      "[CV]  n_estimators=50, min_samples_leaf=100, max_features=0.3, max_depth=4, learning_rate=0.05, total=   2.4s\n",
      "[CV] n_estimators=50, min_samples_leaf=100, max_features=0.3, max_depth=4, learning_rate=0.05 \n",
      "[CV]  n_estimators=50, min_samples_leaf=100, max_features=0.3, max_depth=4, learning_rate=0.05, total=   2.3s\n",
      "[CV] n_estimators=50, min_samples_leaf=100, max_features=0.3, max_depth=4, learning_rate=0.05 \n",
      "[CV]  n_estimators=50, min_samples_leaf=100, max_features=0.3, max_depth=4, learning_rate=0.05, total=   2.3s\n",
      "[CV] n_estimators=50, min_samples_leaf=100, max_features=0.3, max_depth=4, learning_rate=0.05 \n",
      "[CV]  n_estimators=50, min_samples_leaf=100, max_features=0.3, max_depth=4, learning_rate=0.05, total=   2.2s\n",
      "[CV] n_estimators=50, min_samples_leaf=100, max_features=0.3, max_depth=4, learning_rate=0.05 \n",
      "[CV]  n_estimators=50, min_samples_leaf=100, max_features=0.3, max_depth=4, learning_rate=0.05, total=   2.3s\n",
      "[CV] n_estimators=40, min_samples_leaf=150, max_features=0.1, max_depth=4, learning_rate=0.02 \n",
      "[CV]  n_estimators=40, min_samples_leaf=150, max_features=0.1, max_depth=4, learning_rate=0.02, total=   0.9s\n",
      "[CV] n_estimators=40, min_samples_leaf=150, max_features=0.1, max_depth=4, learning_rate=0.02 \n",
      "[CV]  n_estimators=40, min_samples_leaf=150, max_features=0.1, max_depth=4, learning_rate=0.02, total=   0.9s\n",
      "[CV] n_estimators=40, min_samples_leaf=150, max_features=0.1, max_depth=4, learning_rate=0.02 \n",
      "[CV]  n_estimators=40, min_samples_leaf=150, max_features=0.1, max_depth=4, learning_rate=0.02, total=   0.9s\n",
      "[CV] n_estimators=40, min_samples_leaf=150, max_features=0.1, max_depth=4, learning_rate=0.02 \n",
      "[CV]  n_estimators=40, min_samples_leaf=150, max_features=0.1, max_depth=4, learning_rate=0.02, total=   0.9s\n",
      "[CV] n_estimators=40, min_samples_leaf=150, max_features=0.1, max_depth=4, learning_rate=0.02 \n",
      "[CV]  n_estimators=40, min_samples_leaf=150, max_features=0.1, max_depth=4, learning_rate=0.02, total=   0.9s\n",
      "[CV] n_estimators=80, min_samples_leaf=100, max_features=1.0, max_depth=8, learning_rate=0.05 \n",
      "[CV]  n_estimators=80, min_samples_leaf=100, max_features=1.0, max_depth=8, learning_rate=0.05, total=  30.9s\n",
      "[CV] n_estimators=80, min_samples_leaf=100, max_features=1.0, max_depth=8, learning_rate=0.05 \n",
      "[CV]  n_estimators=80, min_samples_leaf=100, max_features=1.0, max_depth=8, learning_rate=0.05, total=  30.3s\n",
      "[CV] n_estimators=80, min_samples_leaf=100, max_features=1.0, max_depth=8, learning_rate=0.05 \n",
      "[CV]  n_estimators=80, min_samples_leaf=100, max_features=1.0, max_depth=8, learning_rate=0.05, total=  30.8s\n",
      "[CV] n_estimators=80, min_samples_leaf=100, max_features=1.0, max_depth=8, learning_rate=0.05 \n",
      "[CV]  n_estimators=80, min_samples_leaf=100, max_features=1.0, max_depth=8, learning_rate=0.05, total=  31.5s\n",
      "[CV] n_estimators=80, min_samples_leaf=100, max_features=1.0, max_depth=8, learning_rate=0.05 \n",
      "[CV]  n_estimators=80, min_samples_leaf=100, max_features=1.0, max_depth=8, learning_rate=0.05, total=  31.3s\n",
      "[CV] n_estimators=40, min_samples_leaf=150, max_features=0.3, max_depth=6, learning_rate=0.1 \n",
      "[CV]  n_estimators=40, min_samples_leaf=150, max_features=0.3, max_depth=6, learning_rate=0.1, total=   3.5s\n",
      "[CV] n_estimators=40, min_samples_leaf=150, max_features=0.3, max_depth=6, learning_rate=0.1 \n",
      "[CV]  n_estimators=40, min_samples_leaf=150, max_features=0.3, max_depth=6, learning_rate=0.1, total=   3.6s\n",
      "[CV] n_estimators=40, min_samples_leaf=150, max_features=0.3, max_depth=6, learning_rate=0.1 \n",
      "[CV]  n_estimators=40, min_samples_leaf=150, max_features=0.3, max_depth=6, learning_rate=0.1, total=   3.4s\n",
      "[CV] n_estimators=40, min_samples_leaf=150, max_features=0.3, max_depth=6, learning_rate=0.1 \n",
      "[CV]  n_estimators=40, min_samples_leaf=150, max_features=0.3, max_depth=6, learning_rate=0.1, total=   3.4s\n",
      "[CV] n_estimators=40, min_samples_leaf=150, max_features=0.3, max_depth=6, learning_rate=0.1 \n",
      "[CV]  n_estimators=40, min_samples_leaf=150, max_features=0.3, max_depth=6, learning_rate=0.1, total=   3.5s\n",
      "[CV] n_estimators=50, min_samples_leaf=20, max_features=0.3, max_depth=8, learning_rate=0.02 \n",
      "[CV]  n_estimators=50, min_samples_leaf=20, max_features=0.3, max_depth=8, learning_rate=0.02, total=  10.0s\n",
      "[CV] n_estimators=50, min_samples_leaf=20, max_features=0.3, max_depth=8, learning_rate=0.02 \n",
      "[CV]  n_estimators=50, min_samples_leaf=20, max_features=0.3, max_depth=8, learning_rate=0.02, total=  10.3s\n",
      "[CV] n_estimators=50, min_samples_leaf=20, max_features=0.3, max_depth=8, learning_rate=0.02 \n",
      "[CV]  n_estimators=50, min_samples_leaf=20, max_features=0.3, max_depth=8, learning_rate=0.02, total=  10.5s\n",
      "[CV] n_estimators=50, min_samples_leaf=20, max_features=0.3, max_depth=8, learning_rate=0.02 \n",
      "[CV]  n_estimators=50, min_samples_leaf=20, max_features=0.3, max_depth=8, learning_rate=0.02, total=   9.7s\n",
      "[CV] n_estimators=50, min_samples_leaf=20, max_features=0.3, max_depth=8, learning_rate=0.02 \n",
      "[CV]  n_estimators=50, min_samples_leaf=20, max_features=0.3, max_depth=8, learning_rate=0.02, total=  10.0s\n",
      "[CV] n_estimators=50, min_samples_leaf=20, max_features=0.1, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=50, min_samples_leaf=20, max_features=0.1, max_depth=6, learning_rate=0.02, total=   2.1s\n",
      "[CV] n_estimators=50, min_samples_leaf=20, max_features=0.1, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=50, min_samples_leaf=20, max_features=0.1, max_depth=6, learning_rate=0.02, total=   2.0s\n",
      "[CV] n_estimators=50, min_samples_leaf=20, max_features=0.1, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=50, min_samples_leaf=20, max_features=0.1, max_depth=6, learning_rate=0.02, total=   2.1s\n",
      "[CV] n_estimators=50, min_samples_leaf=20, max_features=0.1, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=50, min_samples_leaf=20, max_features=0.1, max_depth=6, learning_rate=0.02, total=   2.1s\n",
      "[CV] n_estimators=50, min_samples_leaf=20, max_features=0.1, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=50, min_samples_leaf=20, max_features=0.1, max_depth=6, learning_rate=0.02, total=   2.1s\n",
      "[CV] n_estimators=20, min_samples_leaf=20, max_features=1.0, max_depth=8, learning_rate=0.02 \n",
      "[CV]  n_estimators=20, min_samples_leaf=20, max_features=1.0, max_depth=8, learning_rate=0.02, total=  10.2s\n",
      "[CV] n_estimators=20, min_samples_leaf=20, max_features=1.0, max_depth=8, learning_rate=0.02 \n",
      "[CV]  n_estimators=20, min_samples_leaf=20, max_features=1.0, max_depth=8, learning_rate=0.02, total=  10.8s\n",
      "[CV] n_estimators=20, min_samples_leaf=20, max_features=1.0, max_depth=8, learning_rate=0.02 \n",
      "[CV]  n_estimators=20, min_samples_leaf=20, max_features=1.0, max_depth=8, learning_rate=0.02, total=  11.2s\n",
      "[CV] n_estimators=20, min_samples_leaf=20, max_features=1.0, max_depth=8, learning_rate=0.02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=20, min_samples_leaf=20, max_features=1.0, max_depth=8, learning_rate=0.02, total=  11.4s\n",
      "[CV] n_estimators=20, min_samples_leaf=20, max_features=1.0, max_depth=8, learning_rate=0.02 \n",
      "[CV]  n_estimators=20, min_samples_leaf=20, max_features=1.0, max_depth=8, learning_rate=0.02, total=  11.0s\n",
      "[CV] n_estimators=20, min_samples_leaf=20, max_features=1.0, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=20, min_samples_leaf=20, max_features=1.0, max_depth=6, learning_rate=0.02, total=   6.0s\n",
      "[CV] n_estimators=20, min_samples_leaf=20, max_features=1.0, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=20, min_samples_leaf=20, max_features=1.0, max_depth=6, learning_rate=0.02, total=   5.8s\n",
      "[CV] n_estimators=20, min_samples_leaf=20, max_features=1.0, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=20, min_samples_leaf=20, max_features=1.0, max_depth=6, learning_rate=0.02, total=   6.2s\n",
      "[CV] n_estimators=20, min_samples_leaf=20, max_features=1.0, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=20, min_samples_leaf=20, max_features=1.0, max_depth=6, learning_rate=0.02, total=   5.9s\n",
      "[CV] n_estimators=20, min_samples_leaf=20, max_features=1.0, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=20, min_samples_leaf=20, max_features=1.0, max_depth=6, learning_rate=0.02, total=   5.9s\n",
      "[CV] n_estimators=80, min_samples_leaf=20, max_features=1.0, max_depth=8, learning_rate=0.01 \n",
      "[CV]  n_estimators=80, min_samples_leaf=20, max_features=1.0, max_depth=8, learning_rate=0.01, total=  42.0s\n",
      "[CV] n_estimators=80, min_samples_leaf=20, max_features=1.0, max_depth=8, learning_rate=0.01 \n",
      "[CV]  n_estimators=80, min_samples_leaf=20, max_features=1.0, max_depth=8, learning_rate=0.01, total=  42.3s\n",
      "[CV] n_estimators=80, min_samples_leaf=20, max_features=1.0, max_depth=8, learning_rate=0.01 \n",
      "[CV]  n_estimators=80, min_samples_leaf=20, max_features=1.0, max_depth=8, learning_rate=0.01, total=  43.2s\n",
      "[CV] n_estimators=80, min_samples_leaf=20, max_features=1.0, max_depth=8, learning_rate=0.01 \n",
      "[CV]  n_estimators=80, min_samples_leaf=20, max_features=1.0, max_depth=8, learning_rate=0.01, total=  43.1s\n",
      "[CV] n_estimators=80, min_samples_leaf=20, max_features=1.0, max_depth=8, learning_rate=0.01 \n",
      "[CV]  n_estimators=80, min_samples_leaf=20, max_features=1.0, max_depth=8, learning_rate=0.01, total=  42.9s\n",
      "[CV] n_estimators=20, min_samples_leaf=150, max_features=1.0, max_depth=8, learning_rate=0.01 \n",
      "[CV]  n_estimators=20, min_samples_leaf=150, max_features=1.0, max_depth=8, learning_rate=0.01, total=   9.1s\n",
      "[CV] n_estimators=20, min_samples_leaf=150, max_features=1.0, max_depth=8, learning_rate=0.01 \n",
      "[CV]  n_estimators=20, min_samples_leaf=150, max_features=1.0, max_depth=8, learning_rate=0.01, total=   8.5s\n",
      "[CV] n_estimators=20, min_samples_leaf=150, max_features=1.0, max_depth=8, learning_rate=0.01 \n",
      "[CV]  n_estimators=20, min_samples_leaf=150, max_features=1.0, max_depth=8, learning_rate=0.01, total=   9.1s\n",
      "[CV] n_estimators=20, min_samples_leaf=150, max_features=1.0, max_depth=8, learning_rate=0.01 \n",
      "[CV]  n_estimators=20, min_samples_leaf=150, max_features=1.0, max_depth=8, learning_rate=0.01, total=   9.3s\n",
      "[CV] n_estimators=20, min_samples_leaf=150, max_features=1.0, max_depth=8, learning_rate=0.01 \n",
      "[CV]  n_estimators=20, min_samples_leaf=150, max_features=1.0, max_depth=8, learning_rate=0.01, total=   8.2s\n",
      "[CV] n_estimators=80, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=80, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.05, total=   2.7s\n",
      "[CV] n_estimators=80, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=80, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.05, total=   3.0s\n",
      "[CV] n_estimators=80, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=80, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.05, total=   2.9s\n",
      "[CV] n_estimators=80, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=80, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.05, total=   2.9s\n",
      "[CV] n_estimators=80, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=80, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.05, total=   2.9s\n",
      "[CV] n_estimators=60, min_samples_leaf=150, max_features=0.3, max_depth=6, learning_rate=0.01 \n",
      "[CV]  n_estimators=60, min_samples_leaf=150, max_features=0.3, max_depth=6, learning_rate=0.01, total=   6.2s\n",
      "[CV] n_estimators=60, min_samples_leaf=150, max_features=0.3, max_depth=6, learning_rate=0.01 \n",
      "[CV]  n_estimators=60, min_samples_leaf=150, max_features=0.3, max_depth=6, learning_rate=0.01, total=   6.1s\n",
      "[CV] n_estimators=60, min_samples_leaf=150, max_features=0.3, max_depth=6, learning_rate=0.01 \n",
      "[CV]  n_estimators=60, min_samples_leaf=150, max_features=0.3, max_depth=6, learning_rate=0.01, total=   5.9s\n",
      "[CV] n_estimators=60, min_samples_leaf=150, max_features=0.3, max_depth=6, learning_rate=0.01 \n",
      "[CV]  n_estimators=60, min_samples_leaf=150, max_features=0.3, max_depth=6, learning_rate=0.01, total=   5.9s\n",
      "[CV] n_estimators=60, min_samples_leaf=150, max_features=0.3, max_depth=6, learning_rate=0.01 \n",
      "[CV]  n_estimators=60, min_samples_leaf=150, max_features=0.3, max_depth=6, learning_rate=0.01, total=   6.0s\n",
      "[CV] n_estimators=80, min_samples_leaf=150, max_features=0.3, max_depth=4, learning_rate=0.02 \n",
      "[CV]  n_estimators=80, min_samples_leaf=150, max_features=0.3, max_depth=4, learning_rate=0.02, total=   3.8s\n",
      "[CV] n_estimators=80, min_samples_leaf=150, max_features=0.3, max_depth=4, learning_rate=0.02 \n",
      "[CV]  n_estimators=80, min_samples_leaf=150, max_features=0.3, max_depth=4, learning_rate=0.02, total=   3.8s\n",
      "[CV] n_estimators=80, min_samples_leaf=150, max_features=0.3, max_depth=4, learning_rate=0.02 \n",
      "[CV]  n_estimators=80, min_samples_leaf=150, max_features=0.3, max_depth=4, learning_rate=0.02, total=   3.7s\n",
      "[CV] n_estimators=80, min_samples_leaf=150, max_features=0.3, max_depth=4, learning_rate=0.02 \n",
      "[CV]  n_estimators=80, min_samples_leaf=150, max_features=0.3, max_depth=4, learning_rate=0.02, total=   3.9s\n",
      "[CV] n_estimators=80, min_samples_leaf=150, max_features=0.3, max_depth=4, learning_rate=0.02 \n",
      "[CV]  n_estimators=80, min_samples_leaf=150, max_features=0.3, max_depth=4, learning_rate=0.02, total=   4.0s\n",
      "[CV] n_estimators=70, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=70, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.02, total=   2.6s\n",
      "[CV] n_estimators=70, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=70, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.02, total=   2.6s\n",
      "[CV] n_estimators=70, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=70, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.02, total=   2.6s\n",
      "[CV] n_estimators=70, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=70, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.02, total=   2.7s\n",
      "[CV] n_estimators=70, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=70, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.02, total=   2.6s\n",
      "[CV] n_estimators=30, min_samples_leaf=150, max_features=1.0, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=30, min_samples_leaf=150, max_features=1.0, max_depth=8, learning_rate=0.1, total=  12.2s\n",
      "[CV] n_estimators=30, min_samples_leaf=150, max_features=1.0, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=30, min_samples_leaf=150, max_features=1.0, max_depth=8, learning_rate=0.1, total=  12.8s\n",
      "[CV] n_estimators=30, min_samples_leaf=150, max_features=1.0, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=30, min_samples_leaf=150, max_features=1.0, max_depth=8, learning_rate=0.1, total=  12.7s\n",
      "[CV] n_estimators=30, min_samples_leaf=150, max_features=1.0, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=30, min_samples_leaf=150, max_features=1.0, max_depth=8, learning_rate=0.1, total=  12.5s\n",
      "[CV] n_estimators=30, min_samples_leaf=150, max_features=1.0, max_depth=8, learning_rate=0.1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=30, min_samples_leaf=150, max_features=1.0, max_depth=8, learning_rate=0.1, total=  12.3s\n",
      "[CV] n_estimators=50, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=50, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05, total=   2.0s\n",
      "[CV] n_estimators=50, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=50, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05, total=   2.0s\n",
      "[CV] n_estimators=50, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=50, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05, total=   2.0s\n",
      "[CV] n_estimators=50, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=50, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05, total=   2.2s\n",
      "[CV] n_estimators=50, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=50, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05, total=   2.0s\n",
      "[CV] n_estimators=20, min_samples_leaf=20, max_features=0.3, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=20, min_samples_leaf=20, max_features=0.3, max_depth=6, learning_rate=0.02, total=   2.4s\n",
      "[CV] n_estimators=20, min_samples_leaf=20, max_features=0.3, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=20, min_samples_leaf=20, max_features=0.3, max_depth=6, learning_rate=0.02, total=   2.4s\n",
      "[CV] n_estimators=20, min_samples_leaf=20, max_features=0.3, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=20, min_samples_leaf=20, max_features=0.3, max_depth=6, learning_rate=0.02, total=   2.4s\n",
      "[CV] n_estimators=20, min_samples_leaf=20, max_features=0.3, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=20, min_samples_leaf=20, max_features=0.3, max_depth=6, learning_rate=0.02, total=   2.3s\n",
      "[CV] n_estimators=20, min_samples_leaf=20, max_features=0.3, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=20, min_samples_leaf=20, max_features=0.3, max_depth=6, learning_rate=0.02, total=   2.5s\n",
      "[CV] n_estimators=40, min_samples_leaf=150, max_features=0.1, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=40, min_samples_leaf=150, max_features=0.1, max_depth=8, learning_rate=0.1, total=   2.4s\n",
      "[CV] n_estimators=40, min_samples_leaf=150, max_features=0.1, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=40, min_samples_leaf=150, max_features=0.1, max_depth=8, learning_rate=0.1, total=   2.4s\n",
      "[CV] n_estimators=40, min_samples_leaf=150, max_features=0.1, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=40, min_samples_leaf=150, max_features=0.1, max_depth=8, learning_rate=0.1, total=   2.2s\n",
      "[CV] n_estimators=40, min_samples_leaf=150, max_features=0.1, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=40, min_samples_leaf=150, max_features=0.1, max_depth=8, learning_rate=0.1, total=   2.5s\n",
      "[CV] n_estimators=40, min_samples_leaf=150, max_features=0.1, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=40, min_samples_leaf=150, max_features=0.1, max_depth=8, learning_rate=0.1, total=   2.5s\n",
      "[CV] n_estimators=70, min_samples_leaf=150, max_features=1.0, max_depth=4, learning_rate=0.1 \n",
      "[CV]  n_estimators=70, min_samples_leaf=150, max_features=1.0, max_depth=4, learning_rate=0.1, total=   9.1s\n",
      "[CV] n_estimators=70, min_samples_leaf=150, max_features=1.0, max_depth=4, learning_rate=0.1 \n",
      "[CV]  n_estimators=70, min_samples_leaf=150, max_features=1.0, max_depth=4, learning_rate=0.1, total=   9.4s\n",
      "[CV] n_estimators=70, min_samples_leaf=150, max_features=1.0, max_depth=4, learning_rate=0.1 \n",
      "[CV]  n_estimators=70, min_samples_leaf=150, max_features=1.0, max_depth=4, learning_rate=0.1, total=   8.7s\n",
      "[CV] n_estimators=70, min_samples_leaf=150, max_features=1.0, max_depth=4, learning_rate=0.1 \n",
      "[CV]  n_estimators=70, min_samples_leaf=150, max_features=1.0, max_depth=4, learning_rate=0.1, total=   9.3s\n",
      "[CV] n_estimators=70, min_samples_leaf=150, max_features=1.0, max_depth=4, learning_rate=0.1 \n",
      "[CV]  n_estimators=70, min_samples_leaf=150, max_features=1.0, max_depth=4, learning_rate=0.1, total=   9.2s\n",
      "[CV] n_estimators=60, min_samples_leaf=150, max_features=0.1, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=60, min_samples_leaf=150, max_features=0.1, max_depth=8, learning_rate=0.1, total=   3.4s\n",
      "[CV] n_estimators=60, min_samples_leaf=150, max_features=0.1, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=60, min_samples_leaf=150, max_features=0.1, max_depth=8, learning_rate=0.1, total=   3.2s\n",
      "[CV] n_estimators=60, min_samples_leaf=150, max_features=0.1, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=60, min_samples_leaf=150, max_features=0.1, max_depth=8, learning_rate=0.1, total=   3.0s\n",
      "[CV] n_estimators=60, min_samples_leaf=150, max_features=0.1, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=60, min_samples_leaf=150, max_features=0.1, max_depth=8, learning_rate=0.1, total=   3.0s\n",
      "[CV] n_estimators=60, min_samples_leaf=150, max_features=0.1, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=60, min_samples_leaf=150, max_features=0.1, max_depth=8, learning_rate=0.1, total=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed: 20.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 1229.458s\n",
      "r2: 0.26787986903\n",
      "Mean Absolute Error : 115242.19914\n",
      "Mean Sq Error : 463058976099.0\n",
      "test time:  0.080s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb_grid_params = {\n",
    "    'learning_rate': [0.1, 0.05, 0.02, 0.01],\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'min_samples_leaf': [20, 50,100,150],\n",
    "    'max_features': [1.0, 0.3, 0.1],\n",
    "    'n_estimators':list(range(20,81,10))\n",
    "}\n",
    "clf = KNeighborsRegressor()\n",
    "res = benchmark(clf,train,y_train,test,y_test,gb_grid_params,np.array(train.columns),n_iter=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1,\n",
       " 'max_depth': 8,\n",
       " 'max_features': 0.3,\n",
       " 'min_samples_leaf': 20,\n",
       " 'n_estimators': 50}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[1].sort_values('mean_test_r2',ascending=False).loc[6,'params']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Let's do something for RandomForestRegressor\n",
    "# We will not use OneHotEncoding for categorical \n",
    "\n",
    "data.loc[:,\"material\"]= pd.Categorical(data.material.factorize()[0])\n",
    "data.loc[:,\"location\"]= pd.Categorical(data.location.factorize()[0])\n",
    "data.loc[:,\"category\"]= pd.Categorical(data.category.factorize()[0])\n",
    "data.loc[:,\"artist_nationality\"]= pd.Categorical(data.artist_nationality.factorize()[0])\n",
    "data.loc[:,\"artist_name\"]= pd.Categorical(data.artist_name.factorize()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = list(data.columns)\n",
    "pred.remove(\"hammer_price\")\n",
    "\n",
    "lbl = data[\"hammer_price\"]\n",
    "data = data[pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train,test,y_train,y_test = model_selection.train_test_split(data,lbl,train_size=0.7,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/processed/data.csv\",index_col=0,encoding='latin-1')\n",
    "lbl = data[\"hammer_price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test,y_train,y_test = model_selection.train_test_split(data,lbl,train_size=0.7,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, ..., 0, 0, 1]),\n",
       " Index(['paper', 'sculpture', 'prints', 'canvas', 'other'], dtype='object'))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.materials.factorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_res = tuner(RandomForestRegressor(criterion='mse',n_jobs=4,oob_score=True,verbose=1),train,y_train,\n",
    "               {'n_estimators':[100,500,1000,5000],'max_features':[3,5,0.3,0.5,0.7],'max_depth':[None,10,20]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = pd.DataFrame(cv_res.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_mse</th>\n",
       "      <th>mean_test_r2</th>\n",
       "      <th>mean_train_mse</th>\n",
       "      <th>mean_train_r2</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>...</th>\n",
       "      <th>split4_test_mse</th>\n",
       "      <th>split4_test_r2</th>\n",
       "      <th>split4_train_mse</th>\n",
       "      <th>split4_train_r2</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_mse</th>\n",
       "      <th>std_test_r2</th>\n",
       "      <th>std_train_mse</th>\n",
       "      <th>std_train_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>67.092548</td>\n",
       "      <td>2.929700</td>\n",
       "      <td>-1.569558e+11</td>\n",
       "      <td>0.517289</td>\n",
       "      <td>-2.213067e+10</td>\n",
       "      <td>0.933347</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'n_estimators': 1000, 'max_features': 0.5, 'm...</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.140404e+11</td>\n",
       "      <td>0.638708</td>\n",
       "      <td>-2.319066e+10</td>\n",
       "      <td>0.931251</td>\n",
       "      <td>0.362178</td>\n",
       "      <td>0.070456</td>\n",
       "      <td>7.179151e+10</td>\n",
       "      <td>0.069457</td>\n",
       "      <td>2.182343e+09</td>\n",
       "      <td>0.002230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.430072</td>\n",
       "      <td>1.468859</td>\n",
       "      <td>-1.591920e+11</td>\n",
       "      <td>0.514051</td>\n",
       "      <td>-2.255908e+10</td>\n",
       "      <td>0.932218</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'n_estimators': 500, 'max_features': 5, 'max_...</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.164099e+11</td>\n",
       "      <td>0.631202</td>\n",
       "      <td>-2.389968e+10</td>\n",
       "      <td>0.929149</td>\n",
       "      <td>0.372589</td>\n",
       "      <td>0.012181</td>\n",
       "      <td>7.637502e+10</td>\n",
       "      <td>0.066576</td>\n",
       "      <td>2.646701e+09</td>\n",
       "      <td>0.002599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.720743</td>\n",
       "      <td>1.083194</td>\n",
       "      <td>-1.593090e+11</td>\n",
       "      <td>0.513305</td>\n",
       "      <td>-2.288892e+10</td>\n",
       "      <td>0.931060</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'n_estimators': 500, 'max_features': 5, 'max_...</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.158958e+11</td>\n",
       "      <td>0.632830</td>\n",
       "      <td>-2.425767e+10</td>\n",
       "      <td>0.928087</td>\n",
       "      <td>0.283821</td>\n",
       "      <td>0.003671</td>\n",
       "      <td>7.624939e+10</td>\n",
       "      <td>0.067822</td>\n",
       "      <td>2.272612e+09</td>\n",
       "      <td>0.002650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27.540120</td>\n",
       "      <td>1.093851</td>\n",
       "      <td>-1.588524e+11</td>\n",
       "      <td>0.513162</td>\n",
       "      <td>-2.303963e+10</td>\n",
       "      <td>0.930639</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'n_estimators': 500, 'max_features': 0.5, 'ma...</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.139951e+11</td>\n",
       "      <td>0.638852</td>\n",
       "      <td>-2.425127e+10</td>\n",
       "      <td>0.928106</td>\n",
       "      <td>0.173322</td>\n",
       "      <td>0.006119</td>\n",
       "      <td>7.449349e+10</td>\n",
       "      <td>0.070527</td>\n",
       "      <td>2.352096e+09</td>\n",
       "      <td>0.002231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>35.166905</td>\n",
       "      <td>1.044233</td>\n",
       "      <td>-1.594466e+11</td>\n",
       "      <td>0.509320</td>\n",
       "      <td>-2.311212e+10</td>\n",
       "      <td>0.930325</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>500</td>\n",
       "      <td>{'n_estimators': 500, 'max_features': 0.7, 'ma...</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.139797e+11</td>\n",
       "      <td>0.638901</td>\n",
       "      <td>-2.404704e+10</td>\n",
       "      <td>0.928712</td>\n",
       "      <td>0.146262</td>\n",
       "      <td>0.049709</td>\n",
       "      <td>7.291085e+10</td>\n",
       "      <td>0.072213</td>\n",
       "      <td>2.139182e+09</td>\n",
       "      <td>0.002923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.970424</td>\n",
       "      <td>2.951255</td>\n",
       "      <td>-1.637246e+11</td>\n",
       "      <td>0.503215</td>\n",
       "      <td>-2.269572e+10</td>\n",
       "      <td>0.931688</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'n_estimators': 1000, 'max_features': 3, 'max...</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.209990e+11</td>\n",
       "      <td>0.616663</td>\n",
       "      <td>-2.378535e+10</td>\n",
       "      <td>0.929488</td>\n",
       "      <td>0.342292</td>\n",
       "      <td>0.085187</td>\n",
       "      <td>8.124688e+10</td>\n",
       "      <td>0.065259</td>\n",
       "      <td>2.332496e+09</td>\n",
       "      <td>0.002145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.786625</td>\n",
       "      <td>0.868379</td>\n",
       "      <td>-1.861056e+11</td>\n",
       "      <td>0.423767</td>\n",
       "      <td>-8.596770e+10</td>\n",
       "      <td>0.739743</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'n_estimators': 1000, 'max_features': 0.5, 'm...</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.365282e+11</td>\n",
       "      <td>0.567465</td>\n",
       "      <td>-8.695660e+10</td>\n",
       "      <td>0.742214</td>\n",
       "      <td>0.275454</td>\n",
       "      <td>0.004281</td>\n",
       "      <td>8.155763e+10</td>\n",
       "      <td>0.085170</td>\n",
       "      <td>5.464706e+09</td>\n",
       "      <td>0.018749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.404280</td>\n",
       "      <td>0.458256</td>\n",
       "      <td>-1.902067e+11</td>\n",
       "      <td>0.411089</td>\n",
       "      <td>-9.690743e+10</td>\n",
       "      <td>0.706999</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'n_estimators': 500, 'max_features': 5, 'max_...</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.416323e+11</td>\n",
       "      <td>0.551295</td>\n",
       "      <td>-9.846992e+10</td>\n",
       "      <td>0.708083</td>\n",
       "      <td>0.152121</td>\n",
       "      <td>0.004775</td>\n",
       "      <td>8.366885e+10</td>\n",
       "      <td>0.085325</td>\n",
       "      <td>6.757334e+09</td>\n",
       "      <td>0.017200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.611972</td>\n",
       "      <td>3.519318</td>\n",
       "      <td>-1.939328e+11</td>\n",
       "      <td>0.401574</td>\n",
       "      <td>-1.030388e+11</td>\n",
       "      <td>0.688394</td>\n",
       "      <td>10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5000</td>\n",
       "      <td>{'n_estimators': 5000, 'max_features': 0.3, 'm...</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.447108e+11</td>\n",
       "      <td>0.541542</td>\n",
       "      <td>-1.052149e+11</td>\n",
       "      <td>0.688087</td>\n",
       "      <td>1.870648</td>\n",
       "      <td>0.022443</td>\n",
       "      <td>8.720376e+10</td>\n",
       "      <td>0.084229</td>\n",
       "      <td>7.125959e+09</td>\n",
       "      <td>0.019167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.538806</td>\n",
       "      <td>0.245628</td>\n",
       "      <td>-2.013489e+11</td>\n",
       "      <td>0.377086</td>\n",
       "      <td>-1.137008e+11</td>\n",
       "      <td>0.656473</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'n_estimators': 100, 'max_features': 3, 'max_...</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.542009e+11</td>\n",
       "      <td>0.511476</td>\n",
       "      <td>-1.148783e+11</td>\n",
       "      <td>0.659440</td>\n",
       "      <td>0.051946</td>\n",
       "      <td>0.004342</td>\n",
       "      <td>8.825419e+10</td>\n",
       "      <td>0.084851</td>\n",
       "      <td>8.672395e+09</td>\n",
       "      <td>0.018590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_mse  mean_test_r2  \\\n",
       "9      67.092548         2.929700  -1.569558e+11      0.517289   \n",
       "0      22.430072         1.468859  -1.591920e+11      0.514051   \n",
       "2      19.720743         1.083194  -1.593090e+11      0.513305   \n",
       "5      27.540120         1.093851  -1.588524e+11      0.513162   \n",
       "7      35.166905         1.044233  -1.594466e+11      0.509320   \n",
       "3      35.970424         2.951255  -1.637246e+11      0.503215   \n",
       "4      28.786625         0.868379  -1.861056e+11      0.423767   \n",
       "8      10.404280         0.458256  -1.902067e+11      0.411089   \n",
       "1      88.611972         3.519318  -1.939328e+11      0.401574   \n",
       "6       1.538806         0.245628  -2.013489e+11      0.377086   \n",
       "\n",
       "   mean_train_mse  mean_train_r2 param_max_depth param_max_features  \\\n",
       "9   -2.213067e+10       0.933347            None                0.5   \n",
       "0   -2.255908e+10       0.932218            None                  5   \n",
       "2   -2.288892e+10       0.931060              20                  5   \n",
       "5   -2.303963e+10       0.930639              20                0.5   \n",
       "7   -2.311212e+10       0.930325              20                0.7   \n",
       "3   -2.269572e+10       0.931688            None                  3   \n",
       "4   -8.596770e+10       0.739743              10                0.5   \n",
       "8   -9.690743e+10       0.706999              10                  5   \n",
       "1   -1.030388e+11       0.688394              10                0.3   \n",
       "6   -1.137008e+11       0.656473              10                  3   \n",
       "\n",
       "  param_n_estimators                                             params  \\\n",
       "9               1000  {'n_estimators': 1000, 'max_features': 0.5, 'm...   \n",
       "0                500  {'n_estimators': 500, 'max_features': 5, 'max_...   \n",
       "2                500  {'n_estimators': 500, 'max_features': 5, 'max_...   \n",
       "5                500  {'n_estimators': 500, 'max_features': 0.5, 'ma...   \n",
       "7                500  {'n_estimators': 500, 'max_features': 0.7, 'ma...   \n",
       "3               1000  {'n_estimators': 1000, 'max_features': 3, 'max...   \n",
       "4               1000  {'n_estimators': 1000, 'max_features': 0.5, 'm...   \n",
       "8                500  {'n_estimators': 500, 'max_features': 5, 'max_...   \n",
       "1               5000  {'n_estimators': 5000, 'max_features': 0.3, 'm...   \n",
       "6                100  {'n_estimators': 100, 'max_features': 3, 'max_...   \n",
       "\n",
       "       ...       split4_test_mse  split4_test_r2  split4_train_mse  \\\n",
       "9      ...         -1.140404e+11        0.638708     -2.319066e+10   \n",
       "0      ...         -1.164099e+11        0.631202     -2.389968e+10   \n",
       "2      ...         -1.158958e+11        0.632830     -2.425767e+10   \n",
       "5      ...         -1.139951e+11        0.638852     -2.425127e+10   \n",
       "7      ...         -1.139797e+11        0.638901     -2.404704e+10   \n",
       "3      ...         -1.209990e+11        0.616663     -2.378535e+10   \n",
       "4      ...         -1.365282e+11        0.567465     -8.695660e+10   \n",
       "8      ...         -1.416323e+11        0.551295     -9.846992e+10   \n",
       "1      ...         -1.447108e+11        0.541542     -1.052149e+11   \n",
       "6      ...         -1.542009e+11        0.511476     -1.148783e+11   \n",
       "\n",
       "   split4_train_r2  std_fit_time  std_score_time  std_test_mse  std_test_r2  \\\n",
       "9         0.931251      0.362178        0.070456  7.179151e+10     0.069457   \n",
       "0         0.929149      0.372589        0.012181  7.637502e+10     0.066576   \n",
       "2         0.928087      0.283821        0.003671  7.624939e+10     0.067822   \n",
       "5         0.928106      0.173322        0.006119  7.449349e+10     0.070527   \n",
       "7         0.928712      0.146262        0.049709  7.291085e+10     0.072213   \n",
       "3         0.929488      0.342292        0.085187  8.124688e+10     0.065259   \n",
       "4         0.742214      0.275454        0.004281  8.155763e+10     0.085170   \n",
       "8         0.708083      0.152121        0.004775  8.366885e+10     0.085325   \n",
       "1         0.688087      1.870648        0.022443  8.720376e+10     0.084229   \n",
       "6         0.659440      0.051946        0.004342  8.825419e+10     0.084851   \n",
       "\n",
       "   std_train_mse  std_train_r2  \n",
       "9   2.182343e+09      0.002230  \n",
       "0   2.646701e+09      0.002599  \n",
       "2   2.272612e+09      0.002650  \n",
       "5   2.352096e+09      0.002231  \n",
       "7   2.139182e+09      0.002923  \n",
       "3   2.332496e+09      0.002145  \n",
       "4   5.464706e+09      0.018749  \n",
       "8   6.757334e+09      0.017200  \n",
       "1   7.125959e+09      0.019167  \n",
       "6   8.672395e+09      0.018590  \n",
       "\n",
       "[10 rows x 38 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.sort_values('mean_test_r2',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: 0.423140729039\n",
      "Mean Absolute Error : 85340.5745092\n",
      "Mean Sq Error : 407242682129.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAFxCAYAAACfu3gqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10dde1e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = cv_res.best_estimator_.predict(test)\n",
    "print(\"r2:\",metrics.r2_score(y_test, y_pred))\n",
    "print(\"Mean Absolute Error :\",metrics.mean_absolute_error(y_test, y_pred))\n",
    "print(\"Mean Sq Error :\",metrics.mean_squared_error(y_test, y_pred))\n",
    "importance = cv_res.best_estimator_.feature_importances_\n",
    "x = np.argsort(importance)[-20:]\n",
    "plt.bar(range(0,len(x)),importance[x])\n",
    "plt.xticks(range(0,len(x)),tuple(data.columns.values[x]),rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] n_estimators=50, loss=exponential, learning_rate=0.7, base_estimator__splitter=best, base_estimator__max_features=sqrt \n",
      "[CV]  n_estimators=50, loss=exponential, learning_rate=0.7, base_estimator__splitter=best, base_estimator__max_features=sqrt, total=   5.2s\n",
      "[CV] n_estimators=50, loss=exponential, learning_rate=0.7, base_estimator__splitter=best, base_estimator__max_features=sqrt \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=50, loss=exponential, learning_rate=0.7, base_estimator__splitter=best, base_estimator__max_features=sqrt, total=   8.6s\n",
      "[CV] n_estimators=50, loss=exponential, learning_rate=0.7, base_estimator__splitter=best, base_estimator__max_features=sqrt \n",
      "[CV]  n_estimators=50, loss=exponential, learning_rate=0.7, base_estimator__splitter=best, base_estimator__max_features=sqrt, total=   5.0s\n",
      "[CV] n_estimators=50, loss=exponential, learning_rate=0.7, base_estimator__splitter=best, base_estimator__max_features=sqrt \n",
      "[CV]  n_estimators=50, loss=exponential, learning_rate=0.7, base_estimator__splitter=best, base_estimator__max_features=sqrt, total=   5.7s\n",
      "[CV] n_estimators=50, loss=exponential, learning_rate=0.7, base_estimator__splitter=best, base_estimator__max_features=sqrt \n",
      "[CV]  n_estimators=50, loss=exponential, learning_rate=0.7, base_estimator__splitter=best, base_estimator__max_features=sqrt, total=   7.5s\n",
      "[CV] n_estimators=100, loss=square, learning_rate=0.3, base_estimator__splitter=random, base_estimator__max_features=5 \n",
      "[CV]  n_estimators=100, loss=square, learning_rate=0.3, base_estimator__splitter=random, base_estimator__max_features=5, total=  10.8s\n",
      "[CV] n_estimators=100, loss=square, learning_rate=0.3, base_estimator__splitter=random, base_estimator__max_features=5 \n",
      "[CV]  n_estimators=100, loss=square, learning_rate=0.3, base_estimator__splitter=random, base_estimator__max_features=5, total=  11.0s\n",
      "[CV] n_estimators=100, loss=square, learning_rate=0.3, base_estimator__splitter=random, base_estimator__max_features=5 \n",
      "[CV]  n_estimators=100, loss=square, learning_rate=0.3, base_estimator__splitter=random, base_estimator__max_features=5, total=  10.8s\n",
      "[CV] n_estimators=100, loss=square, learning_rate=0.3, base_estimator__splitter=random, base_estimator__max_features=5 \n",
      "[CV]  n_estimators=100, loss=square, learning_rate=0.3, base_estimator__splitter=random, base_estimator__max_features=5, total=  10.7s\n",
      "[CV] n_estimators=100, loss=square, learning_rate=0.3, base_estimator__splitter=random, base_estimator__max_features=5 \n",
      "[CV]  n_estimators=100, loss=square, learning_rate=0.3, base_estimator__splitter=random, base_estimator__max_features=5, total=  11.1s\n",
      "[CV] n_estimators=50, loss=linear, learning_rate=0.2, base_estimator__splitter=best, base_estimator__max_features=0.3 \n",
      "[CV]  n_estimators=50, loss=linear, learning_rate=0.2, base_estimator__splitter=best, base_estimator__max_features=0.3, total=   8.7s\n",
      "[CV] n_estimators=50, loss=linear, learning_rate=0.2, base_estimator__splitter=best, base_estimator__max_features=0.3 \n",
      "[CV]  n_estimators=50, loss=linear, learning_rate=0.2, base_estimator__splitter=best, base_estimator__max_features=0.3, total=   8.8s\n",
      "[CV] n_estimators=50, loss=linear, learning_rate=0.2, base_estimator__splitter=best, base_estimator__max_features=0.3 \n",
      "[CV]  n_estimators=50, loss=linear, learning_rate=0.2, base_estimator__splitter=best, base_estimator__max_features=0.3, total=   8.6s\n",
      "[CV] n_estimators=50, loss=linear, learning_rate=0.2, base_estimator__splitter=best, base_estimator__max_features=0.3 \n",
      "[CV]  n_estimators=50, loss=linear, learning_rate=0.2, base_estimator__splitter=best, base_estimator__max_features=0.3, total=   8.7s\n",
      "[CV] n_estimators=50, loss=linear, learning_rate=0.2, base_estimator__splitter=best, base_estimator__max_features=0.3 \n",
      "[CV]  n_estimators=50, loss=linear, learning_rate=0.2, base_estimator__splitter=best, base_estimator__max_features=0.3, total=   8.9s\n",
      "[CV] n_estimators=1000, loss=exponential, learning_rate=0.3, base_estimator__splitter=best, base_estimator__max_features=3 \n",
      "[CV]  n_estimators=1000, loss=exponential, learning_rate=0.3, base_estimator__splitter=best, base_estimator__max_features=3, total=  32.7s\n",
      "[CV] n_estimators=1000, loss=exponential, learning_rate=0.3, base_estimator__splitter=best, base_estimator__max_features=3 \n",
      "[CV]  n_estimators=1000, loss=exponential, learning_rate=0.3, base_estimator__splitter=best, base_estimator__max_features=3, total=  58.7s\n",
      "[CV] n_estimators=1000, loss=exponential, learning_rate=0.3, base_estimator__splitter=best, base_estimator__max_features=3 \n",
      "[CV]  n_estimators=1000, loss=exponential, learning_rate=0.3, base_estimator__splitter=best, base_estimator__max_features=3, total=  33.0s\n",
      "[CV] n_estimators=1000, loss=exponential, learning_rate=0.3, base_estimator__splitter=best, base_estimator__max_features=3 \n",
      "[CV]  n_estimators=1000, loss=exponential, learning_rate=0.3, base_estimator__splitter=best, base_estimator__max_features=3, total=  32.3s\n",
      "[CV] n_estimators=1000, loss=exponential, learning_rate=0.3, base_estimator__splitter=best, base_estimator__max_features=3 \n",
      "[CV]  n_estimators=1000, loss=exponential, learning_rate=0.3, base_estimator__splitter=best, base_estimator__max_features=3, total=  52.2s\n",
      "[CV] n_estimators=100, loss=exponential, learning_rate=0.7, base_estimator__splitter=random, base_estimator__max_features=sqrt \n",
      "[CV]  n_estimators=100, loss=exponential, learning_rate=0.7, base_estimator__splitter=random, base_estimator__max_features=sqrt, total=   4.9s\n",
      "[CV] n_estimators=100, loss=exponential, learning_rate=0.7, base_estimator__splitter=random, base_estimator__max_features=sqrt \n",
      "[CV]  n_estimators=100, loss=exponential, learning_rate=0.7, base_estimator__splitter=random, base_estimator__max_features=sqrt, total=   8.3s\n",
      "[CV] n_estimators=100, loss=exponential, learning_rate=0.7, base_estimator__splitter=random, base_estimator__max_features=sqrt \n",
      "[CV]  n_estimators=100, loss=exponential, learning_rate=0.7, base_estimator__splitter=random, base_estimator__max_features=sqrt, total=   4.9s\n",
      "[CV] n_estimators=100, loss=exponential, learning_rate=0.7, base_estimator__splitter=random, base_estimator__max_features=sqrt \n",
      "[CV]  n_estimators=100, loss=exponential, learning_rate=0.7, base_estimator__splitter=random, base_estimator__max_features=sqrt, total=   4.7s\n",
      "[CV] n_estimators=100, loss=exponential, learning_rate=0.7, base_estimator__splitter=random, base_estimator__max_features=sqrt \n",
      "[CV]  n_estimators=100, loss=exponential, learning_rate=0.7, base_estimator__splitter=random, base_estimator__max_features=sqrt, total=   6.7s\n",
      "[CV] n_estimators=1000, loss=exponential, learning_rate=0.7, base_estimator__splitter=random, base_estimator__max_features=0.3 \n",
      "[CV]  n_estimators=1000, loss=exponential, learning_rate=0.7, base_estimator__splitter=random, base_estimator__max_features=0.3, total=  31.1s\n",
      "[CV] n_estimators=1000, loss=exponential, learning_rate=0.7, base_estimator__splitter=random, base_estimator__max_features=0.3 \n",
      "[CV]  n_estimators=1000, loss=exponential, learning_rate=0.7, base_estimator__splitter=random, base_estimator__max_features=0.3, total=  45.3s\n",
      "[CV] n_estimators=1000, loss=exponential, learning_rate=0.7, base_estimator__splitter=random, base_estimator__max_features=0.3 \n",
      "[CV]  n_estimators=1000, loss=exponential, learning_rate=0.7, base_estimator__splitter=random, base_estimator__max_features=0.3, total=  31.2s\n",
      "[CV] n_estimators=1000, loss=exponential, learning_rate=0.7, base_estimator__splitter=random, base_estimator__max_features=0.3 \n",
      "[CV]  n_estimators=1000, loss=exponential, learning_rate=0.7, base_estimator__splitter=random, base_estimator__max_features=0.3, total=  30.6s\n",
      "[CV] n_estimators=1000, loss=exponential, learning_rate=0.7, base_estimator__splitter=random, base_estimator__max_features=0.3 \n",
      "[CV]  n_estimators=1000, loss=exponential, learning_rate=0.7, base_estimator__splitter=random, base_estimator__max_features=0.3, total=  44.9s\n",
      "[CV] n_estimators=50, loss=square, learning_rate=0.2, base_estimator__splitter=best, base_estimator__max_features=0.3 \n",
      "[CV]  n_estimators=50, loss=square, learning_rate=0.2, base_estimator__splitter=best, base_estimator__max_features=0.3, total=   9.1s\n",
      "[CV] n_estimators=50, loss=square, learning_rate=0.2, base_estimator__splitter=best, base_estimator__max_features=0.3 \n",
      "[CV]  n_estimators=50, loss=square, learning_rate=0.2, base_estimator__splitter=best, base_estimator__max_features=0.3, total=   9.0s\n",
      "[CV] n_estimators=50, loss=square, learning_rate=0.2, base_estimator__splitter=best, base_estimator__max_features=0.3 \n",
      "[CV]  n_estimators=50, loss=square, learning_rate=0.2, base_estimator__splitter=best, base_estimator__max_features=0.3, total=   9.0s\n",
      "[CV] n_estimators=50, loss=square, learning_rate=0.2, base_estimator__splitter=best, base_estimator__max_features=0.3 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=50, loss=square, learning_rate=0.2, base_estimator__splitter=best, base_estimator__max_features=0.3, total=   8.9s\n",
      "[CV] n_estimators=50, loss=square, learning_rate=0.2, base_estimator__splitter=best, base_estimator__max_features=0.3 \n",
      "[CV]  n_estimators=50, loss=square, learning_rate=0.2, base_estimator__splitter=best, base_estimator__max_features=0.3, total=   9.1s\n",
      "[CV] n_estimators=100, loss=linear, learning_rate=0.1, base_estimator__splitter=random, base_estimator__max_features=3 \n",
      "[CV]  n_estimators=100, loss=linear, learning_rate=0.1, base_estimator__splitter=random, base_estimator__max_features=3, total=   9.2s\n",
      "[CV] n_estimators=100, loss=linear, learning_rate=0.1, base_estimator__splitter=random, base_estimator__max_features=3 \n",
      "[CV]  n_estimators=100, loss=linear, learning_rate=0.1, base_estimator__splitter=random, base_estimator__max_features=3, total=   9.5s\n",
      "[CV] n_estimators=100, loss=linear, learning_rate=0.1, base_estimator__splitter=random, base_estimator__max_features=3 \n",
      "[CV]  n_estimators=100, loss=linear, learning_rate=0.1, base_estimator__splitter=random, base_estimator__max_features=3, total=   9.1s\n",
      "[CV] n_estimators=100, loss=linear, learning_rate=0.1, base_estimator__splitter=random, base_estimator__max_features=3 \n",
      "[CV]  n_estimators=100, loss=linear, learning_rate=0.1, base_estimator__splitter=random, base_estimator__max_features=3, total=   9.1s\n",
      "[CV] n_estimators=100, loss=linear, learning_rate=0.1, base_estimator__splitter=random, base_estimator__max_features=3 \n",
      "[CV]  n_estimators=100, loss=linear, learning_rate=0.1, base_estimator__splitter=random, base_estimator__max_features=3, total=   9.4s\n",
      "[CV] n_estimators=500, loss=exponential, learning_rate=0.7, base_estimator__splitter=best, base_estimator__max_features=sqrt \n",
      "[CV]  n_estimators=500, loss=exponential, learning_rate=0.7, base_estimator__splitter=best, base_estimator__max_features=sqrt, total=  17.2s\n",
      "[CV] n_estimators=500, loss=exponential, learning_rate=0.7, base_estimator__splitter=best, base_estimator__max_features=sqrt \n",
      "[CV]  n_estimators=500, loss=exponential, learning_rate=0.7, base_estimator__splitter=best, base_estimator__max_features=sqrt, total=  32.0s\n",
      "[CV] n_estimators=500, loss=exponential, learning_rate=0.7, base_estimator__splitter=best, base_estimator__max_features=sqrt \n",
      "[CV]  n_estimators=500, loss=exponential, learning_rate=0.7, base_estimator__splitter=best, base_estimator__max_features=sqrt, total=  16.9s\n",
      "[CV] n_estimators=500, loss=exponential, learning_rate=0.7, base_estimator__splitter=best, base_estimator__max_features=sqrt \n",
      "[CV]  n_estimators=500, loss=exponential, learning_rate=0.7, base_estimator__splitter=best, base_estimator__max_features=sqrt, total=  16.7s\n",
      "[CV] n_estimators=500, loss=exponential, learning_rate=0.7, base_estimator__splitter=best, base_estimator__max_features=sqrt \n",
      "[CV]  n_estimators=500, loss=exponential, learning_rate=0.7, base_estimator__splitter=best, base_estimator__max_features=sqrt, total=  28.6s\n",
      "[CV] n_estimators=100, loss=square, learning_rate=0.5, base_estimator__splitter=random, base_estimator__max_features=0.3 \n",
      "[CV]  n_estimators=100, loss=square, learning_rate=0.5, base_estimator__splitter=random, base_estimator__max_features=0.3, total=   9.0s\n",
      "[CV] n_estimators=100, loss=square, learning_rate=0.5, base_estimator__splitter=random, base_estimator__max_features=0.3 \n",
      "[CV]  n_estimators=100, loss=square, learning_rate=0.5, base_estimator__splitter=random, base_estimator__max_features=0.3, total=   9.9s\n",
      "[CV] n_estimators=100, loss=square, learning_rate=0.5, base_estimator__splitter=random, base_estimator__max_features=0.3 \n",
      "[CV]  n_estimators=100, loss=square, learning_rate=0.5, base_estimator__splitter=random, base_estimator__max_features=0.3, total=   8.4s\n",
      "[CV] n_estimators=100, loss=square, learning_rate=0.5, base_estimator__splitter=random, base_estimator__max_features=0.3 \n",
      "[CV]  n_estimators=100, loss=square, learning_rate=0.5, base_estimator__splitter=random, base_estimator__max_features=0.3, total=   9.0s\n",
      "[CV] n_estimators=100, loss=square, learning_rate=0.5, base_estimator__splitter=random, base_estimator__max_features=0.3 \n",
      "[CV]  n_estimators=100, loss=square, learning_rate=0.5, base_estimator__splitter=random, base_estimator__max_features=0.3, total=   9.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed: 18.6min finished\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators':[100,50,500,1000],\n",
    "    'learning_rate':[0.1,0.2,0.3,0.5,0.7],\n",
    "    'loss':['linear','square','exponential'],\n",
    "    'base_estimator__splitter' : ['best','random'],\n",
    "    'base_estimator__max_features' : [3,5,'sqrt',0.3],\n",
    "}\n",
    "cv_res_adaboost = tuner(AdaBoostRegressor(base_estimator=tree.DecisionTreeRegressor(max_features=3)),train,y_train,params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_mse</th>\n",
       "      <th>mean_test_r2</th>\n",
       "      <th>mean_train_mse</th>\n",
       "      <th>mean_train_r2</th>\n",
       "      <th>param_base_estimator__max_features</th>\n",
       "      <th>param_base_estimator__splitter</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>...</th>\n",
       "      <th>split4_test_mse</th>\n",
       "      <th>split4_test_r2</th>\n",
       "      <th>split4_train_mse</th>\n",
       "      <th>split4_train_r2</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_mse</th>\n",
       "      <th>std_test_r2</th>\n",
       "      <th>std_train_mse</th>\n",
       "      <th>std_train_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.279154</td>\n",
       "      <td>0.460921</td>\n",
       "      <td>-1.788599e+11</td>\n",
       "      <td>0.461187</td>\n",
       "      <td>-6.655561e+08</td>\n",
       "      <td>0.998104</td>\n",
       "      <td>0.3</td>\n",
       "      <td>best</td>\n",
       "      <td>0.2</td>\n",
       "      <td>linear</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.207270e+11</td>\n",
       "      <td>0.617525</td>\n",
       "      <td>-2.228998e+08</td>\n",
       "      <td>0.999339</td>\n",
       "      <td>0.103124</td>\n",
       "      <td>0.003255</td>\n",
       "      <td>9.456454e+10</td>\n",
       "      <td>0.084288</td>\n",
       "      <td>4.265107e+08</td>\n",
       "      <td>0.001180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.992971</td>\n",
       "      <td>0.412674</td>\n",
       "      <td>-1.823733e+11</td>\n",
       "      <td>0.448401</td>\n",
       "      <td>-1.151512e+09</td>\n",
       "      <td>0.996736</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>best</td>\n",
       "      <td>0.7</td>\n",
       "      <td>exponential</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.383946e+11</td>\n",
       "      <td>0.561552</td>\n",
       "      <td>-2.322599e+08</td>\n",
       "      <td>0.999311</td>\n",
       "      <td>1.392589</td>\n",
       "      <td>0.035517</td>\n",
       "      <td>9.117823e+10</td>\n",
       "      <td>0.064750</td>\n",
       "      <td>8.327704e+08</td>\n",
       "      <td>0.002322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.550949</td>\n",
       "      <td>0.465354</td>\n",
       "      <td>-1.866453e+11</td>\n",
       "      <td>0.436100</td>\n",
       "      <td>-6.826912e+08</td>\n",
       "      <td>0.998046</td>\n",
       "      <td>0.3</td>\n",
       "      <td>best</td>\n",
       "      <td>0.2</td>\n",
       "      <td>square</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.480071e+11</td>\n",
       "      <td>0.531098</td>\n",
       "      <td>-2.367597e+08</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.053245</td>\n",
       "      <td>0.006352</td>\n",
       "      <td>9.231632e+10</td>\n",
       "      <td>0.056481</td>\n",
       "      <td>4.159625e+08</td>\n",
       "      <td>0.001139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.303378</td>\n",
       "      <td>0.609383</td>\n",
       "      <td>-1.961311e+11</td>\n",
       "      <td>0.412811</td>\n",
       "      <td>-1.944535e+09</td>\n",
       "      <td>0.994445</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7</td>\n",
       "      <td>exponential</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.591636e+11</td>\n",
       "      <td>0.495754</td>\n",
       "      <td>-4.488775e+08</td>\n",
       "      <td>0.998669</td>\n",
       "      <td>1.307914</td>\n",
       "      <td>0.109960</td>\n",
       "      <td>9.977070e+10</td>\n",
       "      <td>0.044593</td>\n",
       "      <td>1.444526e+09</td>\n",
       "      <td>0.004199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.002795</td>\n",
       "      <td>0.891004</td>\n",
       "      <td>-2.027470e+11</td>\n",
       "      <td>0.381958</td>\n",
       "      <td>-6.590063e+08</td>\n",
       "      <td>0.998123</td>\n",
       "      <td>5</td>\n",
       "      <td>random</td>\n",
       "      <td>0.3</td>\n",
       "      <td>square</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.523689e+11</td>\n",
       "      <td>0.517280</td>\n",
       "      <td>-2.223639e+08</td>\n",
       "      <td>0.999341</td>\n",
       "      <td>0.153296</td>\n",
       "      <td>0.009338</td>\n",
       "      <td>9.751162e+10</td>\n",
       "      <td>0.082375</td>\n",
       "      <td>4.221787e+08</td>\n",
       "      <td>0.001168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.189947</td>\n",
       "      <td>4.585849</td>\n",
       "      <td>-1.966660e+11</td>\n",
       "      <td>0.371423</td>\n",
       "      <td>-3.971300e+10</td>\n",
       "      <td>0.887814</td>\n",
       "      <td>3</td>\n",
       "      <td>best</td>\n",
       "      <td>0.3</td>\n",
       "      <td>exponential</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.161593e+11</td>\n",
       "      <td>0.631995</td>\n",
       "      <td>-8.938415e+09</td>\n",
       "      <td>0.973502</td>\n",
       "      <td>10.659654</td>\n",
       "      <td>0.681436</td>\n",
       "      <td>8.177035e+10</td>\n",
       "      <td>0.162786</td>\n",
       "      <td>2.839430e+10</td>\n",
       "      <td>0.078794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.350986</td>\n",
       "      <td>0.858638</td>\n",
       "      <td>-2.058536e+11</td>\n",
       "      <td>0.362083</td>\n",
       "      <td>-8.210790e+08</td>\n",
       "      <td>0.997673</td>\n",
       "      <td>0.3</td>\n",
       "      <td>random</td>\n",
       "      <td>0.5</td>\n",
       "      <td>square</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.532724e+11</td>\n",
       "      <td>0.514418</td>\n",
       "      <td>-2.341707e+08</td>\n",
       "      <td>0.999306</td>\n",
       "      <td>0.509350</td>\n",
       "      <td>0.027082</td>\n",
       "      <td>9.472500e+10</td>\n",
       "      <td>0.117968</td>\n",
       "      <td>5.647955e+08</td>\n",
       "      <td>0.001539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.360503</td>\n",
       "      <td>0.913021</td>\n",
       "      <td>-2.108697e+11</td>\n",
       "      <td>0.358485</td>\n",
       "      <td>-6.592450e+08</td>\n",
       "      <td>0.998122</td>\n",
       "      <td>3</td>\n",
       "      <td>random</td>\n",
       "      <td>0.1</td>\n",
       "      <td>linear</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.692809e+11</td>\n",
       "      <td>0.463701</td>\n",
       "      <td>-2.218822e+08</td>\n",
       "      <td>0.999342</td>\n",
       "      <td>0.139262</td>\n",
       "      <td>0.011825</td>\n",
       "      <td>9.872190e+10</td>\n",
       "      <td>0.058053</td>\n",
       "      <td>4.228275e+08</td>\n",
       "      <td>0.001170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20.122646</td>\n",
       "      <td>2.152881</td>\n",
       "      <td>-1.992432e+11</td>\n",
       "      <td>0.358443</td>\n",
       "      <td>-4.649803e+10</td>\n",
       "      <td>0.868425</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>best</td>\n",
       "      <td>0.7</td>\n",
       "      <td>exponential</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.144291e+11</td>\n",
       "      <td>0.637477</td>\n",
       "      <td>-1.012594e+10</td>\n",
       "      <td>0.969981</td>\n",
       "      <td>6.335249</td>\n",
       "      <td>0.331134</td>\n",
       "      <td>8.055833e+10</td>\n",
       "      <td>0.179053</td>\n",
       "      <td>3.325407e+10</td>\n",
       "      <td>0.092658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32.362473</td>\n",
       "      <td>4.258186</td>\n",
       "      <td>-2.706157e+11</td>\n",
       "      <td>0.067529</td>\n",
       "      <td>-1.137289e+11</td>\n",
       "      <td>0.678027</td>\n",
       "      <td>0.3</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7</td>\n",
       "      <td>exponential</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.631954e+11</td>\n",
       "      <td>0.482981</td>\n",
       "      <td>-2.998693e+10</td>\n",
       "      <td>0.911103</td>\n",
       "      <td>6.376950</td>\n",
       "      <td>0.604619</td>\n",
       "      <td>7.008558e+10</td>\n",
       "      <td>0.351636</td>\n",
       "      <td>8.077825e+10</td>\n",
       "      <td>0.223571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_mse  mean_test_r2  \\\n",
       "2       8.279154         0.460921  -1.788599e+11      0.461187   \n",
       "0       5.992971         0.412674  -1.823733e+11      0.448401   \n",
       "6       8.550949         0.465354  -1.866453e+11      0.436100   \n",
       "4       5.303378         0.609383  -1.961311e+11      0.412811   \n",
       "1      10.002795         0.891004  -2.027470e+11      0.381958   \n",
       "3      37.189947         4.585849  -1.966660e+11      0.371423   \n",
       "9       8.350986         0.858638  -2.058536e+11      0.362083   \n",
       "7       8.360503         0.913021  -2.108697e+11      0.358485   \n",
       "8      20.122646         2.152881  -1.992432e+11      0.358443   \n",
       "5      32.362473         4.258186  -2.706157e+11      0.067529   \n",
       "\n",
       "   mean_train_mse  mean_train_r2 param_base_estimator__max_features  \\\n",
       "2   -6.655561e+08       0.998104                                0.3   \n",
       "0   -1.151512e+09       0.996736                               sqrt   \n",
       "6   -6.826912e+08       0.998046                                0.3   \n",
       "4   -1.944535e+09       0.994445                               sqrt   \n",
       "1   -6.590063e+08       0.998123                                  5   \n",
       "3   -3.971300e+10       0.887814                                  3   \n",
       "9   -8.210790e+08       0.997673                                0.3   \n",
       "7   -6.592450e+08       0.998122                                  3   \n",
       "8   -4.649803e+10       0.868425                               sqrt   \n",
       "5   -1.137289e+11       0.678027                                0.3   \n",
       "\n",
       "  param_base_estimator__splitter param_learning_rate   param_loss  \\\n",
       "2                           best                 0.2       linear   \n",
       "0                           best                 0.7  exponential   \n",
       "6                           best                 0.2       square   \n",
       "4                         random                 0.7  exponential   \n",
       "1                         random                 0.3       square   \n",
       "3                           best                 0.3  exponential   \n",
       "9                         random                 0.5       square   \n",
       "7                         random                 0.1       linear   \n",
       "8                           best                 0.7  exponential   \n",
       "5                         random                 0.7  exponential   \n",
       "\n",
       "       ...      split4_test_mse split4_test_r2  split4_train_mse  \\\n",
       "2      ...        -1.207270e+11       0.617525     -2.228998e+08   \n",
       "0      ...        -1.383946e+11       0.561552     -2.322599e+08   \n",
       "6      ...        -1.480071e+11       0.531098     -2.367597e+08   \n",
       "4      ...        -1.591636e+11       0.495754     -4.488775e+08   \n",
       "1      ...        -1.523689e+11       0.517280     -2.223639e+08   \n",
       "3      ...        -1.161593e+11       0.631995     -8.938415e+09   \n",
       "9      ...        -1.532724e+11       0.514418     -2.341707e+08   \n",
       "7      ...        -1.692809e+11       0.463701     -2.218822e+08   \n",
       "8      ...        -1.144291e+11       0.637477     -1.012594e+10   \n",
       "5      ...        -1.631954e+11       0.482981     -2.998693e+10   \n",
       "\n",
       "   split4_train_r2  std_fit_time  std_score_time  std_test_mse  std_test_r2  \\\n",
       "2         0.999339      0.103124        0.003255  9.456454e+10     0.084288   \n",
       "0         0.999311      1.392589        0.035517  9.117823e+10     0.064750   \n",
       "6         0.999298      0.053245        0.006352  9.231632e+10     0.056481   \n",
       "4         0.998669      1.307914        0.109960  9.977070e+10     0.044593   \n",
       "1         0.999341      0.153296        0.009338  9.751162e+10     0.082375   \n",
       "3         0.973502     10.659654        0.681436  8.177035e+10     0.162786   \n",
       "9         0.999306      0.509350        0.027082  9.472500e+10     0.117968   \n",
       "7         0.999342      0.139262        0.011825  9.872190e+10     0.058053   \n",
       "8         0.969981      6.335249        0.331134  8.055833e+10     0.179053   \n",
       "5         0.911103      6.376950        0.604619  7.008558e+10     0.351636   \n",
       "\n",
       "   std_train_mse  std_train_r2  \n",
       "2   4.265107e+08      0.001180  \n",
       "0   8.327704e+08      0.002322  \n",
       "6   4.159625e+08      0.001139  \n",
       "4   1.444526e+09      0.004199  \n",
       "1   4.221787e+08      0.001168  \n",
       "3   2.839430e+10      0.078794  \n",
       "9   5.647955e+08      0.001539  \n",
       "7   4.228275e+08      0.001170  \n",
       "8   3.325407e+10      0.092658  \n",
       "5   8.077825e+10      0.223571  \n",
       "\n",
       "[10 rows x 40 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv_res_adaboost.cv_results_).sort_values('mean_test_r2',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: 0.43992179198\n",
      "Mean Absolute Error : 60243.5552902\n",
      "Mean Sq Error : 395395832430.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAFxCAYAAABz4t95AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ea77da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = cv_res_adaboost.best_estimator_.predict(test)\n",
    "print(\"r2:\",metrics.r2_score(y_test, y_pred))\n",
    "print(\"Mean Absolute Error :\",metrics.mean_absolute_error(y_test, y_pred))\n",
    "print(\"Mean Sq Error :\",metrics.mean_squared_error(y_test, y_pred))\n",
    "importance = cv_res_adaboost.best_estimator_.feature_importances_\n",
    "x = np.argsort(importance)[-20:]\n",
    "plt.bar(range(0,len(x)),importance[x])\n",
    "plt.xticks(range(0,len(x)),tuple(data.columns.values[x]),rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    6.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: 0.934398590958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    6.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error : 29078.3925968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    5.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Sq Error : 21844665684.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 1000 out of 1000 | elapsed:    6.8s finished\n"
     ]
    }
   ],
   "source": [
    "print(\"r2:\",metrics.r2_score(y_train, clf.predict(train)))\n",
    "print(\"Mean Absolute Error :\",metrics.mean_absolute_error(y_train, clf.predict(train)))\n",
    "print(\"Mean Sq Error :\",metrics.mean_squared_error(y_train, clf.predict(train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "GradientBoostingRegressor\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV] n_estimators=60, min_samples_leaf=20, max_features=0.3, max_depth=4, learning_rate=0.01 \n",
      "[CV]  n_estimators=60, min_samples_leaf=20, max_features=0.3, max_depth=4, learning_rate=0.01, total=   3.4s\n",
      "[CV] n_estimators=60, min_samples_leaf=20, max_features=0.3, max_depth=4, learning_rate=0.01 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=60, min_samples_leaf=20, max_features=0.3, max_depth=4, learning_rate=0.01, total=   3.6s\n",
      "[CV] n_estimators=60, min_samples_leaf=20, max_features=0.3, max_depth=4, learning_rate=0.01 \n",
      "[CV]  n_estimators=60, min_samples_leaf=20, max_features=0.3, max_depth=4, learning_rate=0.01, total=   3.9s\n",
      "[CV] n_estimators=60, min_samples_leaf=20, max_features=0.3, max_depth=4, learning_rate=0.01 \n",
      "[CV]  n_estimators=60, min_samples_leaf=20, max_features=0.3, max_depth=4, learning_rate=0.01, total=   4.1s\n",
      "[CV] n_estimators=60, min_samples_leaf=20, max_features=0.3, max_depth=4, learning_rate=0.01 \n",
      "[CV]  n_estimators=60, min_samples_leaf=20, max_features=0.3, max_depth=4, learning_rate=0.01, total=   4.1s\n",
      "[CV] n_estimators=70, min_samples_leaf=20, max_features=1.0, max_depth=8, learning_rate=0.02 \n",
      "[CV]  n_estimators=70, min_samples_leaf=20, max_features=1.0, max_depth=8, learning_rate=0.02, total=  41.2s\n",
      "[CV] n_estimators=70, min_samples_leaf=20, max_features=1.0, max_depth=8, learning_rate=0.02 \n",
      "[CV]  n_estimators=70, min_samples_leaf=20, max_features=1.0, max_depth=8, learning_rate=0.02, total=  43.3s\n",
      "[CV] n_estimators=70, min_samples_leaf=20, max_features=1.0, max_depth=8, learning_rate=0.02 \n",
      "[CV]  n_estimators=70, min_samples_leaf=20, max_features=1.0, max_depth=8, learning_rate=0.02, total=  41.3s\n",
      "[CV] n_estimators=70, min_samples_leaf=20, max_features=1.0, max_depth=8, learning_rate=0.02 \n",
      "[CV]  n_estimators=70, min_samples_leaf=20, max_features=1.0, max_depth=8, learning_rate=0.02, total=  42.7s\n",
      "[CV] n_estimators=70, min_samples_leaf=20, max_features=1.0, max_depth=8, learning_rate=0.02 \n",
      "[CV]  n_estimators=70, min_samples_leaf=20, max_features=1.0, max_depth=8, learning_rate=0.02, total=  42.3s\n",
      "[CV] n_estimators=30, min_samples_leaf=50, max_features=0.3, max_depth=8, learning_rate=0.05 \n",
      "[CV]  n_estimators=30, min_samples_leaf=50, max_features=0.3, max_depth=8, learning_rate=0.05, total=   5.4s\n",
      "[CV] n_estimators=30, min_samples_leaf=50, max_features=0.3, max_depth=8, learning_rate=0.05 \n",
      "[CV]  n_estimators=30, min_samples_leaf=50, max_features=0.3, max_depth=8, learning_rate=0.05, total=   5.8s\n",
      "[CV] n_estimators=30, min_samples_leaf=50, max_features=0.3, max_depth=8, learning_rate=0.05 \n",
      "[CV]  n_estimators=30, min_samples_leaf=50, max_features=0.3, max_depth=8, learning_rate=0.05, total=   5.5s\n",
      "[CV] n_estimators=30, min_samples_leaf=50, max_features=0.3, max_depth=8, learning_rate=0.05 \n",
      "[CV]  n_estimators=30, min_samples_leaf=50, max_features=0.3, max_depth=8, learning_rate=0.05, total=   5.6s\n",
      "[CV] n_estimators=30, min_samples_leaf=50, max_features=0.3, max_depth=8, learning_rate=0.05 \n",
      "[CV]  n_estimators=30, min_samples_leaf=50, max_features=0.3, max_depth=8, learning_rate=0.05, total=   5.8s\n",
      "[CV] n_estimators=60, min_samples_leaf=100, max_features=0.1, max_depth=4, learning_rate=0.05 \n",
      "[CV]  n_estimators=60, min_samples_leaf=100, max_features=0.1, max_depth=4, learning_rate=0.05, total=   1.7s\n",
      "[CV] n_estimators=60, min_samples_leaf=100, max_features=0.1, max_depth=4, learning_rate=0.05 \n",
      "[CV]  n_estimators=60, min_samples_leaf=100, max_features=0.1, max_depth=4, learning_rate=0.05, total=   1.8s\n",
      "[CV] n_estimators=60, min_samples_leaf=100, max_features=0.1, max_depth=4, learning_rate=0.05 \n",
      "[CV]  n_estimators=60, min_samples_leaf=100, max_features=0.1, max_depth=4, learning_rate=0.05, total=   1.8s\n",
      "[CV] n_estimators=60, min_samples_leaf=100, max_features=0.1, max_depth=4, learning_rate=0.05 \n",
      "[CV]  n_estimators=60, min_samples_leaf=100, max_features=0.1, max_depth=4, learning_rate=0.05, total=   2.0s\n",
      "[CV] n_estimators=60, min_samples_leaf=100, max_features=0.1, max_depth=4, learning_rate=0.05 \n",
      "[CV]  n_estimators=60, min_samples_leaf=100, max_features=0.1, max_depth=4, learning_rate=0.05, total=   1.8s\n",
      "[CV] n_estimators=60, min_samples_leaf=100, max_features=1.0, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=60, min_samples_leaf=100, max_features=1.0, max_depth=6, learning_rate=0.02, total=  18.3s\n",
      "[CV] n_estimators=60, min_samples_leaf=100, max_features=1.0, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=60, min_samples_leaf=100, max_features=1.0, max_depth=6, learning_rate=0.02, total=  19.4s\n",
      "[CV] n_estimators=60, min_samples_leaf=100, max_features=1.0, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=60, min_samples_leaf=100, max_features=1.0, max_depth=6, learning_rate=0.02, total=  18.7s\n",
      "[CV] n_estimators=60, min_samples_leaf=100, max_features=1.0, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=60, min_samples_leaf=100, max_features=1.0, max_depth=6, learning_rate=0.02, total=  18.3s\n",
      "[CV] n_estimators=60, min_samples_leaf=100, max_features=1.0, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=60, min_samples_leaf=100, max_features=1.0, max_depth=6, learning_rate=0.02, total=  19.3s\n",
      "[CV] n_estimators=60, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=60, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.02, total=   2.8s\n",
      "[CV] n_estimators=60, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=60, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.02, total=   2.0s\n",
      "[CV] n_estimators=60, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=60, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.02, total=   1.5s\n",
      "[CV] n_estimators=60, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=60, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.02, total=   1.3s\n",
      "[CV] n_estimators=60, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=60, min_samples_leaf=150, max_features=0.1, max_depth=6, learning_rate=0.02, total=   1.2s\n",
      "[CV] n_estimators=60, min_samples_leaf=50, max_features=1.0, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=60, min_samples_leaf=50, max_features=1.0, max_depth=8, learning_rate=0.1, total=  11.3s\n",
      "[CV] n_estimators=60, min_samples_leaf=50, max_features=1.0, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=60, min_samples_leaf=50, max_features=1.0, max_depth=8, learning_rate=0.1, total=  11.2s\n",
      "[CV] n_estimators=60, min_samples_leaf=50, max_features=1.0, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=60, min_samples_leaf=50, max_features=1.0, max_depth=8, learning_rate=0.1, total=  11.2s\n",
      "[CV] n_estimators=60, min_samples_leaf=50, max_features=1.0, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=60, min_samples_leaf=50, max_features=1.0, max_depth=8, learning_rate=0.1, total=  11.6s\n",
      "[CV] n_estimators=60, min_samples_leaf=50, max_features=1.0, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=60, min_samples_leaf=50, max_features=1.0, max_depth=8, learning_rate=0.1, total=  11.2s\n",
      "[CV] n_estimators=20, min_samples_leaf=150, max_features=1.0, max_depth=4, learning_rate=0.05 \n",
      "[CV]  n_estimators=20, min_samples_leaf=150, max_features=1.0, max_depth=4, learning_rate=0.05, total=   1.3s\n",
      "[CV] n_estimators=20, min_samples_leaf=150, max_features=1.0, max_depth=4, learning_rate=0.05 \n",
      "[CV]  n_estimators=20, min_samples_leaf=150, max_features=1.0, max_depth=4, learning_rate=0.05, total=   1.3s\n",
      "[CV] n_estimators=20, min_samples_leaf=150, max_features=1.0, max_depth=4, learning_rate=0.05 \n",
      "[CV]  n_estimators=20, min_samples_leaf=150, max_features=1.0, max_depth=4, learning_rate=0.05, total=   1.4s\n",
      "[CV] n_estimators=20, min_samples_leaf=150, max_features=1.0, max_depth=4, learning_rate=0.05 \n",
      "[CV]  n_estimators=20, min_samples_leaf=150, max_features=1.0, max_depth=4, learning_rate=0.05, total=   1.4s\n",
      "[CV] n_estimators=20, min_samples_leaf=150, max_features=1.0, max_depth=4, learning_rate=0.05 \n",
      "[CV]  n_estimators=20, min_samples_leaf=150, max_features=1.0, max_depth=4, learning_rate=0.05, total=   1.4s\n",
      "[CV] n_estimators=20, min_samples_leaf=100, max_features=1.0, max_depth=8, learning_rate=0.01 \n",
      "[CV]  n_estimators=20, min_samples_leaf=100, max_features=1.0, max_depth=8, learning_rate=0.01, total=   5.1s\n",
      "[CV] n_estimators=20, min_samples_leaf=100, max_features=1.0, max_depth=8, learning_rate=0.01 \n",
      "[CV]  n_estimators=20, min_samples_leaf=100, max_features=1.0, max_depth=8, learning_rate=0.01, total=   5.1s\n",
      "[CV] n_estimators=20, min_samples_leaf=100, max_features=1.0, max_depth=8, learning_rate=0.01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=20, min_samples_leaf=100, max_features=1.0, max_depth=8, learning_rate=0.01, total=   5.1s\n",
      "[CV] n_estimators=20, min_samples_leaf=100, max_features=1.0, max_depth=8, learning_rate=0.01 \n",
      "[CV]  n_estimators=20, min_samples_leaf=100, max_features=1.0, max_depth=8, learning_rate=0.01, total=   4.9s\n",
      "[CV] n_estimators=20, min_samples_leaf=100, max_features=1.0, max_depth=8, learning_rate=0.01 \n",
      "[CV]  n_estimators=20, min_samples_leaf=100, max_features=1.0, max_depth=8, learning_rate=0.01, total=   5.1s\n",
      "[CV] n_estimators=80, min_samples_leaf=100, max_features=0.1, max_depth=4, learning_rate=0.1 \n",
      "[CV]  n_estimators=80, min_samples_leaf=100, max_features=0.1, max_depth=4, learning_rate=0.1, total=   0.9s\n",
      "[CV] n_estimators=80, min_samples_leaf=100, max_features=0.1, max_depth=4, learning_rate=0.1 \n",
      "[CV]  n_estimators=80, min_samples_leaf=100, max_features=0.1, max_depth=4, learning_rate=0.1, total=   0.9s\n",
      "[CV] n_estimators=80, min_samples_leaf=100, max_features=0.1, max_depth=4, learning_rate=0.1 \n",
      "[CV]  n_estimators=80, min_samples_leaf=100, max_features=0.1, max_depth=4, learning_rate=0.1, total=   0.9s\n",
      "[CV] n_estimators=80, min_samples_leaf=100, max_features=0.1, max_depth=4, learning_rate=0.1 \n",
      "[CV]  n_estimators=80, min_samples_leaf=100, max_features=0.1, max_depth=4, learning_rate=0.1, total=   0.9s\n",
      "[CV] n_estimators=80, min_samples_leaf=100, max_features=0.1, max_depth=4, learning_rate=0.1 \n",
      "[CV]  n_estimators=80, min_samples_leaf=100, max_features=0.1, max_depth=4, learning_rate=0.1, total=   0.9s\n",
      "[CV] n_estimators=20, min_samples_leaf=20, max_features=0.1, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=20, min_samples_leaf=20, max_features=0.1, max_depth=6, learning_rate=0.02, total=   0.5s\n",
      "[CV] n_estimators=20, min_samples_leaf=20, max_features=0.1, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=20, min_samples_leaf=20, max_features=0.1, max_depth=6, learning_rate=0.02, total=   0.5s\n",
      "[CV] n_estimators=20, min_samples_leaf=20, max_features=0.1, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=20, min_samples_leaf=20, max_features=0.1, max_depth=6, learning_rate=0.02, total=   0.5s\n",
      "[CV] n_estimators=20, min_samples_leaf=20, max_features=0.1, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=20, min_samples_leaf=20, max_features=0.1, max_depth=6, learning_rate=0.02, total=   0.5s\n",
      "[CV] n_estimators=20, min_samples_leaf=20, max_features=0.1, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=20, min_samples_leaf=20, max_features=0.1, max_depth=6, learning_rate=0.02, total=   0.5s\n",
      "[CV] n_estimators=30, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=30, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05, total=   0.7s\n",
      "[CV] n_estimators=30, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=30, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05, total=   0.7s\n",
      "[CV] n_estimators=30, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=30, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05, total=   0.7s\n",
      "[CV] n_estimators=30, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=30, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05, total=   0.6s\n",
      "[CV] n_estimators=30, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=30, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05, total=   0.7s\n",
      "[CV] n_estimators=70, min_samples_leaf=150, max_features=1.0, max_depth=6, learning_rate=0.01 \n",
      "[CV]  n_estimators=70, min_samples_leaf=150, max_features=1.0, max_depth=6, learning_rate=0.01, total=  10.5s\n",
      "[CV] n_estimators=70, min_samples_leaf=150, max_features=1.0, max_depth=6, learning_rate=0.01 \n",
      "[CV]  n_estimators=70, min_samples_leaf=150, max_features=1.0, max_depth=6, learning_rate=0.01, total=  10.0s\n",
      "[CV] n_estimators=70, min_samples_leaf=150, max_features=1.0, max_depth=6, learning_rate=0.01 \n",
      "[CV]  n_estimators=70, min_samples_leaf=150, max_features=1.0, max_depth=6, learning_rate=0.01, total=  22.9s\n",
      "[CV] n_estimators=70, min_samples_leaf=150, max_features=1.0, max_depth=6, learning_rate=0.01 \n",
      "[CV]  n_estimators=70, min_samples_leaf=150, max_features=1.0, max_depth=6, learning_rate=0.01, total=   9.4s\n",
      "[CV] n_estimators=70, min_samples_leaf=150, max_features=1.0, max_depth=6, learning_rate=0.01 \n",
      "[CV]  n_estimators=70, min_samples_leaf=150, max_features=1.0, max_depth=6, learning_rate=0.01, total=   9.2s\n",
      "[CV] n_estimators=60, min_samples_leaf=20, max_features=1.0, max_depth=4, learning_rate=0.05 \n",
      "[CV]  n_estimators=60, min_samples_leaf=20, max_features=1.0, max_depth=4, learning_rate=0.05, total=   4.0s\n",
      "[CV] n_estimators=60, min_samples_leaf=20, max_features=1.0, max_depth=4, learning_rate=0.05 \n",
      "[CV]  n_estimators=60, min_samples_leaf=20, max_features=1.0, max_depth=4, learning_rate=0.05, total=   4.0s\n",
      "[CV] n_estimators=60, min_samples_leaf=20, max_features=1.0, max_depth=4, learning_rate=0.05 \n",
      "[CV]  n_estimators=60, min_samples_leaf=20, max_features=1.0, max_depth=4, learning_rate=0.05, total=   9.0s\n",
      "[CV] n_estimators=60, min_samples_leaf=20, max_features=1.0, max_depth=4, learning_rate=0.05 \n",
      "[CV]  n_estimators=60, min_samples_leaf=20, max_features=1.0, max_depth=4, learning_rate=0.05, total=   4.5s\n",
      "[CV] n_estimators=60, min_samples_leaf=20, max_features=1.0, max_depth=4, learning_rate=0.05 \n",
      "[CV]  n_estimators=60, min_samples_leaf=20, max_features=1.0, max_depth=4, learning_rate=0.05, total=   4.0s\n",
      "[CV] n_estimators=30, min_samples_leaf=50, max_features=1.0, max_depth=6, learning_rate=0.01 \n",
      "[CV]  n_estimators=30, min_samples_leaf=50, max_features=1.0, max_depth=6, learning_rate=0.01, total=   4.3s\n",
      "[CV] n_estimators=30, min_samples_leaf=50, max_features=1.0, max_depth=6, learning_rate=0.01 \n",
      "[CV]  n_estimators=30, min_samples_leaf=50, max_features=1.0, max_depth=6, learning_rate=0.01, total=   4.7s\n",
      "[CV] n_estimators=30, min_samples_leaf=50, max_features=1.0, max_depth=6, learning_rate=0.01 \n",
      "[CV]  n_estimators=30, min_samples_leaf=50, max_features=1.0, max_depth=6, learning_rate=0.01, total=   4.2s\n",
      "[CV] n_estimators=30, min_samples_leaf=50, max_features=1.0, max_depth=6, learning_rate=0.01 \n",
      "[CV]  n_estimators=30, min_samples_leaf=50, max_features=1.0, max_depth=6, learning_rate=0.01, total=   4.4s\n",
      "[CV] n_estimators=30, min_samples_leaf=50, max_features=1.0, max_depth=6, learning_rate=0.01 \n",
      "[CV]  n_estimators=30, min_samples_leaf=50, max_features=1.0, max_depth=6, learning_rate=0.01, total=   4.4s\n",
      "[CV] n_estimators=80, min_samples_leaf=100, max_features=1.0, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=80, min_samples_leaf=100, max_features=1.0, max_depth=6, learning_rate=0.02, total=  10.2s\n",
      "[CV] n_estimators=80, min_samples_leaf=100, max_features=1.0, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=80, min_samples_leaf=100, max_features=1.0, max_depth=6, learning_rate=0.02, total=  11.2s\n",
      "[CV] n_estimators=80, min_samples_leaf=100, max_features=1.0, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=80, min_samples_leaf=100, max_features=1.0, max_depth=6, learning_rate=0.02, total=  10.5s\n",
      "[CV] n_estimators=80, min_samples_leaf=100, max_features=1.0, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=80, min_samples_leaf=100, max_features=1.0, max_depth=6, learning_rate=0.02, total=  10.5s\n",
      "[CV] n_estimators=80, min_samples_leaf=100, max_features=1.0, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=80, min_samples_leaf=100, max_features=1.0, max_depth=6, learning_rate=0.02, total=  10.6s\n",
      "[CV] n_estimators=70, min_samples_leaf=50, max_features=0.1, max_depth=8, learning_rate=0.05 \n",
      "[CV]  n_estimators=70, min_samples_leaf=50, max_features=0.1, max_depth=8, learning_rate=0.05, total=   2.2s\n",
      "[CV] n_estimators=70, min_samples_leaf=50, max_features=0.1, max_depth=8, learning_rate=0.05 \n",
      "[CV]  n_estimators=70, min_samples_leaf=50, max_features=0.1, max_depth=8, learning_rate=0.05, total=   2.1s\n",
      "[CV] n_estimators=70, min_samples_leaf=50, max_features=0.1, max_depth=8, learning_rate=0.05 \n",
      "[CV]  n_estimators=70, min_samples_leaf=50, max_features=0.1, max_depth=8, learning_rate=0.05, total=   2.0s\n",
      "[CV] n_estimators=70, min_samples_leaf=50, max_features=0.1, max_depth=8, learning_rate=0.05 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=70, min_samples_leaf=50, max_features=0.1, max_depth=8, learning_rate=0.05, total=   2.1s\n",
      "[CV] n_estimators=70, min_samples_leaf=50, max_features=0.1, max_depth=8, learning_rate=0.05 \n",
      "[CV]  n_estimators=70, min_samples_leaf=50, max_features=0.1, max_depth=8, learning_rate=0.05, total=   2.4s\n",
      "[CV] n_estimators=80, min_samples_leaf=50, max_features=0.1, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=80, min_samples_leaf=50, max_features=0.1, max_depth=8, learning_rate=0.1, total=   2.4s\n",
      "[CV] n_estimators=80, min_samples_leaf=50, max_features=0.1, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=80, min_samples_leaf=50, max_features=0.1, max_depth=8, learning_rate=0.1, total=   4.6s\n",
      "[CV] n_estimators=80, min_samples_leaf=50, max_features=0.1, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=80, min_samples_leaf=50, max_features=0.1, max_depth=8, learning_rate=0.1, total=   2.9s\n",
      "[CV] n_estimators=80, min_samples_leaf=50, max_features=0.1, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=80, min_samples_leaf=50, max_features=0.1, max_depth=8, learning_rate=0.1, total=   2.2s\n",
      "[CV] n_estimators=80, min_samples_leaf=50, max_features=0.1, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=80, min_samples_leaf=50, max_features=0.1, max_depth=8, learning_rate=0.1, total=   2.4s\n",
      "[CV] n_estimators=70, min_samples_leaf=20, max_features=0.3, max_depth=4, learning_rate=0.05 \n",
      "[CV]  n_estimators=70, min_samples_leaf=20, max_features=0.3, max_depth=4, learning_rate=0.05, total=   1.7s\n",
      "[CV] n_estimators=70, min_samples_leaf=20, max_features=0.3, max_depth=4, learning_rate=0.05 \n",
      "[CV]  n_estimators=70, min_samples_leaf=20, max_features=0.3, max_depth=4, learning_rate=0.05, total=   1.6s\n",
      "[CV] n_estimators=70, min_samples_leaf=20, max_features=0.3, max_depth=4, learning_rate=0.05 \n",
      "[CV]  n_estimators=70, min_samples_leaf=20, max_features=0.3, max_depth=4, learning_rate=0.05, total=   1.7s\n",
      "[CV] n_estimators=70, min_samples_leaf=20, max_features=0.3, max_depth=4, learning_rate=0.05 \n",
      "[CV]  n_estimators=70, min_samples_leaf=20, max_features=0.3, max_depth=4, learning_rate=0.05, total=   1.8s\n",
      "[CV] n_estimators=70, min_samples_leaf=20, max_features=0.3, max_depth=4, learning_rate=0.05 \n",
      "[CV]  n_estimators=70, min_samples_leaf=20, max_features=0.3, max_depth=4, learning_rate=0.05, total=   1.6s\n",
      "[CV] n_estimators=60, min_samples_leaf=150, max_features=0.3, max_depth=8, learning_rate=0.02 \n",
      "[CV]  n_estimators=60, min_samples_leaf=150, max_features=0.3, max_depth=8, learning_rate=0.02, total=   3.9s\n",
      "[CV] n_estimators=60, min_samples_leaf=150, max_features=0.3, max_depth=8, learning_rate=0.02 \n",
      "[CV]  n_estimators=60, min_samples_leaf=150, max_features=0.3, max_depth=8, learning_rate=0.02, total=   4.2s\n",
      "[CV] n_estimators=60, min_samples_leaf=150, max_features=0.3, max_depth=8, learning_rate=0.02 \n",
      "[CV]  n_estimators=60, min_samples_leaf=150, max_features=0.3, max_depth=8, learning_rate=0.02, total=   5.7s\n",
      "[CV] n_estimators=60, min_samples_leaf=150, max_features=0.3, max_depth=8, learning_rate=0.02 \n",
      "[CV]  n_estimators=60, min_samples_leaf=150, max_features=0.3, max_depth=8, learning_rate=0.02, total=   5.9s\n",
      "[CV] n_estimators=60, min_samples_leaf=150, max_features=0.3, max_depth=8, learning_rate=0.02 \n",
      "[CV]  n_estimators=60, min_samples_leaf=150, max_features=0.3, max_depth=8, learning_rate=0.02, total=   4.6s\n",
      "[CV] n_estimators=80, min_samples_leaf=20, max_features=0.1, max_depth=4, learning_rate=0.01 \n",
      "[CV]  n_estimators=80, min_samples_leaf=20, max_features=0.1, max_depth=4, learning_rate=0.01, total=   1.0s\n",
      "[CV] n_estimators=80, min_samples_leaf=20, max_features=0.1, max_depth=4, learning_rate=0.01 \n",
      "[CV]  n_estimators=80, min_samples_leaf=20, max_features=0.1, max_depth=4, learning_rate=0.01, total=   0.9s\n",
      "[CV] n_estimators=80, min_samples_leaf=20, max_features=0.1, max_depth=4, learning_rate=0.01 \n",
      "[CV]  n_estimators=80, min_samples_leaf=20, max_features=0.1, max_depth=4, learning_rate=0.01, total=   1.0s\n",
      "[CV] n_estimators=80, min_samples_leaf=20, max_features=0.1, max_depth=4, learning_rate=0.01 \n",
      "[CV]  n_estimators=80, min_samples_leaf=20, max_features=0.1, max_depth=4, learning_rate=0.01, total=   0.9s\n",
      "[CV] n_estimators=80, min_samples_leaf=20, max_features=0.1, max_depth=4, learning_rate=0.01 \n",
      "[CV]  n_estimators=80, min_samples_leaf=20, max_features=0.1, max_depth=4, learning_rate=0.01, total=   1.0s\n",
      "[CV] n_estimators=70, min_samples_leaf=150, max_features=1.0, max_depth=4, learning_rate=0.01 \n",
      "[CV]  n_estimators=70, min_samples_leaf=150, max_features=1.0, max_depth=4, learning_rate=0.01, total=   4.5s\n",
      "[CV] n_estimators=70, min_samples_leaf=150, max_features=1.0, max_depth=4, learning_rate=0.01 \n",
      "[CV]  n_estimators=70, min_samples_leaf=150, max_features=1.0, max_depth=4, learning_rate=0.01, total=   6.0s\n",
      "[CV] n_estimators=70, min_samples_leaf=150, max_features=1.0, max_depth=4, learning_rate=0.01 \n",
      "[CV]  n_estimators=70, min_samples_leaf=150, max_features=1.0, max_depth=4, learning_rate=0.01, total=   9.5s\n",
      "[CV] n_estimators=70, min_samples_leaf=150, max_features=1.0, max_depth=4, learning_rate=0.01 \n",
      "[CV]  n_estimators=70, min_samples_leaf=150, max_features=1.0, max_depth=4, learning_rate=0.01, total=  10.0s\n",
      "[CV] n_estimators=70, min_samples_leaf=150, max_features=1.0, max_depth=4, learning_rate=0.01 \n",
      "[CV]  n_estimators=70, min_samples_leaf=150, max_features=1.0, max_depth=4, learning_rate=0.01, total=   4.4s\n",
      "[CV] n_estimators=70, min_samples_leaf=100, max_features=1.0, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=70, min_samples_leaf=100, max_features=1.0, max_depth=8, learning_rate=0.1, total=  13.4s\n",
      "[CV] n_estimators=70, min_samples_leaf=100, max_features=1.0, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=70, min_samples_leaf=100, max_features=1.0, max_depth=8, learning_rate=0.1, total=  18.1s\n",
      "[CV] n_estimators=70, min_samples_leaf=100, max_features=1.0, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=70, min_samples_leaf=100, max_features=1.0, max_depth=8, learning_rate=0.1, total=  24.4s\n",
      "[CV] n_estimators=70, min_samples_leaf=100, max_features=1.0, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=70, min_samples_leaf=100, max_features=1.0, max_depth=8, learning_rate=0.1, total=  17.9s\n",
      "[CV] n_estimators=70, min_samples_leaf=100, max_features=1.0, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=70, min_samples_leaf=100, max_features=1.0, max_depth=8, learning_rate=0.1, total=  12.3s\n",
      "[CV] n_estimators=20, min_samples_leaf=150, max_features=1.0, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=20, min_samples_leaf=150, max_features=1.0, max_depth=6, learning_rate=0.02, total=   2.9s\n",
      "[CV] n_estimators=20, min_samples_leaf=150, max_features=1.0, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=20, min_samples_leaf=150, max_features=1.0, max_depth=6, learning_rate=0.02, total=   3.0s\n",
      "[CV] n_estimators=20, min_samples_leaf=150, max_features=1.0, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=20, min_samples_leaf=150, max_features=1.0, max_depth=6, learning_rate=0.02, total=   3.3s\n",
      "[CV] n_estimators=20, min_samples_leaf=150, max_features=1.0, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=20, min_samples_leaf=150, max_features=1.0, max_depth=6, learning_rate=0.02, total=   4.1s\n",
      "[CV] n_estimators=20, min_samples_leaf=150, max_features=1.0, max_depth=6, learning_rate=0.02 \n",
      "[CV]  n_estimators=20, min_samples_leaf=150, max_features=1.0, max_depth=6, learning_rate=0.02, total=   6.4s\n",
      "[CV] n_estimators=70, min_samples_leaf=20, max_features=0.1, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=70, min_samples_leaf=20, max_features=0.1, max_depth=8, learning_rate=0.1, total=   3.2s\n",
      "[CV] n_estimators=70, min_samples_leaf=20, max_features=0.1, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=70, min_samples_leaf=20, max_features=0.1, max_depth=8, learning_rate=0.1, total=   4.8s\n",
      "[CV] n_estimators=70, min_samples_leaf=20, max_features=0.1, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=70, min_samples_leaf=20, max_features=0.1, max_depth=8, learning_rate=0.1, total=   4.8s\n",
      "[CV] n_estimators=70, min_samples_leaf=20, max_features=0.1, max_depth=8, learning_rate=0.1 \n",
      "[CV]  n_estimators=70, min_samples_leaf=20, max_features=0.1, max_depth=8, learning_rate=0.1, total=   4.9s\n",
      "[CV] n_estimators=70, min_samples_leaf=20, max_features=0.1, max_depth=8, learning_rate=0.1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=70, min_samples_leaf=20, max_features=0.1, max_depth=8, learning_rate=0.1, total=   4.7s\n",
      "[CV] n_estimators=80, min_samples_leaf=20, max_features=0.3, max_depth=8, learning_rate=0.02 \n",
      "[CV]  n_estimators=80, min_samples_leaf=20, max_features=0.3, max_depth=8, learning_rate=0.02, total=  15.4s\n",
      "[CV] n_estimators=80, min_samples_leaf=20, max_features=0.3, max_depth=8, learning_rate=0.02 \n",
      "[CV]  n_estimators=80, min_samples_leaf=20, max_features=0.3, max_depth=8, learning_rate=0.02, total=  16.0s\n",
      "[CV] n_estimators=80, min_samples_leaf=20, max_features=0.3, max_depth=8, learning_rate=0.02 \n",
      "[CV]  n_estimators=80, min_samples_leaf=20, max_features=0.3, max_depth=8, learning_rate=0.02, total=  15.8s\n",
      "[CV] n_estimators=80, min_samples_leaf=20, max_features=0.3, max_depth=8, learning_rate=0.02 \n",
      "[CV]  n_estimators=80, min_samples_leaf=20, max_features=0.3, max_depth=8, learning_rate=0.02, total=  16.2s\n",
      "[CV] n_estimators=80, min_samples_leaf=20, max_features=0.3, max_depth=8, learning_rate=0.02 \n",
      "[CV]  n_estimators=80, min_samples_leaf=20, max_features=0.3, max_depth=8, learning_rate=0.02, total=  16.1s\n",
      "[CV] n_estimators=20, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=20, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05, total=   1.1s\n",
      "[CV] n_estimators=20, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=20, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05, total=   1.2s\n",
      "[CV] n_estimators=20, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=20, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05, total=   1.1s\n",
      "[CV] n_estimators=20, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=20, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05, total=   1.2s\n",
      "[CV] n_estimators=20, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=20, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05, total=   1.1s\n",
      "[CV] n_estimators=20, min_samples_leaf=100, max_features=0.3, max_depth=4, learning_rate=0.05 \n",
      "[CV]  n_estimators=20, min_samples_leaf=100, max_features=0.3, max_depth=4, learning_rate=0.05, total=   1.4s\n",
      "[CV] n_estimators=20, min_samples_leaf=100, max_features=0.3, max_depth=4, learning_rate=0.05 \n",
      "[CV]  n_estimators=20, min_samples_leaf=100, max_features=0.3, max_depth=4, learning_rate=0.05, total=   1.4s\n",
      "[CV] n_estimators=20, min_samples_leaf=100, max_features=0.3, max_depth=4, learning_rate=0.05 \n",
      "[CV]  n_estimators=20, min_samples_leaf=100, max_features=0.3, max_depth=4, learning_rate=0.05, total=   1.3s\n",
      "[CV] n_estimators=20, min_samples_leaf=100, max_features=0.3, max_depth=4, learning_rate=0.05 \n",
      "[CV]  n_estimators=20, min_samples_leaf=100, max_features=0.3, max_depth=4, learning_rate=0.05, total=   1.4s\n",
      "[CV] n_estimators=20, min_samples_leaf=100, max_features=0.3, max_depth=4, learning_rate=0.05 \n",
      "[CV]  n_estimators=20, min_samples_leaf=100, max_features=0.3, max_depth=4, learning_rate=0.05, total=   1.4s\n",
      "[CV] n_estimators=60, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=60, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05, total=   2.8s\n",
      "[CV] n_estimators=60, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=60, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05, total=   2.7s\n",
      "[CV] n_estimators=60, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=60, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05, total=   2.8s\n",
      "[CV] n_estimators=60, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=60, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05, total=   2.8s\n",
      "[CV] n_estimators=60, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05 \n",
      "[CV]  n_estimators=60, min_samples_leaf=100, max_features=0.1, max_depth=6, learning_rate=0.05, total=   2.8s\n",
      "[CV] n_estimators=40, min_samples_leaf=20, max_features=0.3, max_depth=4, learning_rate=0.02 \n",
      "[CV]  n_estimators=40, min_samples_leaf=20, max_features=0.3, max_depth=4, learning_rate=0.02, total=   2.4s\n",
      "[CV] n_estimators=40, min_samples_leaf=20, max_features=0.3, max_depth=4, learning_rate=0.02 \n",
      "[CV]  n_estimators=40, min_samples_leaf=20, max_features=0.3, max_depth=4, learning_rate=0.02, total=   2.4s\n",
      "[CV] n_estimators=40, min_samples_leaf=20, max_features=0.3, max_depth=4, learning_rate=0.02 \n",
      "[CV]  n_estimators=40, min_samples_leaf=20, max_features=0.3, max_depth=4, learning_rate=0.02, total=   2.5s\n",
      "[CV] n_estimators=40, min_samples_leaf=20, max_features=0.3, max_depth=4, learning_rate=0.02 \n",
      "[CV]  n_estimators=40, min_samples_leaf=20, max_features=0.3, max_depth=4, learning_rate=0.02, total=   2.4s\n",
      "[CV] n_estimators=40, min_samples_leaf=20, max_features=0.3, max_depth=4, learning_rate=0.02 \n",
      "[CV]  n_estimators=40, min_samples_leaf=20, max_features=0.3, max_depth=4, learning_rate=0.02, total=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed: 17.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 1075.761s\n",
      "r2: 0.274235037641\n",
      "Mean Absolute Error : 111680.035275\n",
      "Mean Sq Error : 512364947129.0\n",
      "test time:  0.187s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb_grid_params = {\n",
    "    'learning_rate': [0.1, 0.05, 0.02, 0.01],\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'min_samples_leaf': [20, 50,100,150],\n",
    "    'max_features': [1.0, 0.3, 0.1],\n",
    "    'n_estimators':list(range(20,81,10))\n",
    "}\n",
    "clf = GradientBoostingRegressor()\n",
    "res = benchmark(clf,train,y_train,test,y_test,gb_grid_params,np.array(train.columns),n_iter=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_mse</th>\n",
       "      <th>mean_test_r2</th>\n",
       "      <th>mean_train_mse</th>\n",
       "      <th>mean_train_r2</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>...</th>\n",
       "      <th>split4_test_mse</th>\n",
       "      <th>split4_test_r2</th>\n",
       "      <th>split4_train_mse</th>\n",
       "      <th>split4_train_r2</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_mse</th>\n",
       "      <th>std_test_r2</th>\n",
       "      <th>std_train_mse</th>\n",
       "      <th>std_train_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.677182</td>\n",
       "      <td>0.133705</td>\n",
       "      <td>-3.092229e+11</td>\n",
       "      <td>0.074522</td>\n",
       "      <td>-3.037309e+11</td>\n",
       "      <td>0.087037</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.889174e+11</td>\n",
       "      <td>0.084681</td>\n",
       "      <td>-3.105650e+11</td>\n",
       "      <td>0.079320</td>\n",
       "      <td>0.275039</td>\n",
       "      <td>0.006721</td>\n",
       "      <td>1.496828e+11</td>\n",
       "      <td>0.009902</td>\n",
       "      <td>3.373494e+10</td>\n",
       "      <td>0.008631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.970156</td>\n",
       "      <td>0.201472</td>\n",
       "      <td>-2.583374e+11</td>\n",
       "      <td>0.231846</td>\n",
       "      <td>-2.278631e+11</td>\n",
       "      <td>0.315189</td>\n",
       "      <td>0.02</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.359228e+11</td>\n",
       "      <td>0.252573</td>\n",
       "      <td>-2.300173e+11</td>\n",
       "      <td>0.318106</td>\n",
       "      <td>0.817238</td>\n",
       "      <td>0.004731</td>\n",
       "      <td>1.310998e+11</td>\n",
       "      <td>0.028790</td>\n",
       "      <td>2.583633e+10</td>\n",
       "      <td>0.008343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.496951</td>\n",
       "      <td>0.127762</td>\n",
       "      <td>-2.715555e+11</td>\n",
       "      <td>0.197096</td>\n",
       "      <td>-2.555767e+11</td>\n",
       "      <td>0.232927</td>\n",
       "      <td>0.05</td>\n",
       "      <td>8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.510849e+11</td>\n",
       "      <td>0.204538</td>\n",
       "      <td>-2.586266e+11</td>\n",
       "      <td>0.233293</td>\n",
       "      <td>0.148698</td>\n",
       "      <td>0.003568</td>\n",
       "      <td>1.395634e+11</td>\n",
       "      <td>0.029904</td>\n",
       "      <td>3.121153e+10</td>\n",
       "      <td>0.007312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.678362</td>\n",
       "      <td>0.135600</td>\n",
       "      <td>-3.001876e+11</td>\n",
       "      <td>0.107518</td>\n",
       "      <td>-2.961826e+11</td>\n",
       "      <td>0.110913</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.830079e+11</td>\n",
       "      <td>0.103403</td>\n",
       "      <td>-3.012389e+11</td>\n",
       "      <td>0.106968</td>\n",
       "      <td>0.075116</td>\n",
       "      <td>0.010641</td>\n",
       "      <td>1.497048e+11</td>\n",
       "      <td>0.020035</td>\n",
       "      <td>3.590904e+10</td>\n",
       "      <td>0.004921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.633569</td>\n",
       "      <td>0.155022</td>\n",
       "      <td>-2.873511e+11</td>\n",
       "      <td>0.147606</td>\n",
       "      <td>-2.799286e+11</td>\n",
       "      <td>0.160181</td>\n",
       "      <td>0.02</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.707783e+11</td>\n",
       "      <td>0.142147</td>\n",
       "      <td>-2.831700e+11</td>\n",
       "      <td>0.160534</td>\n",
       "      <td>0.483051</td>\n",
       "      <td>0.003959</td>\n",
       "      <td>1.448758e+11</td>\n",
       "      <td>0.023719</td>\n",
       "      <td>3.511027e+10</td>\n",
       "      <td>0.008894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.694261</td>\n",
       "      <td>0.099786</td>\n",
       "      <td>-3.048876e+11</td>\n",
       "      <td>0.093417</td>\n",
       "      <td>-3.018425e+11</td>\n",
       "      <td>0.093892</td>\n",
       "      <td>0.02</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.863462e+11</td>\n",
       "      <td>0.092826</td>\n",
       "      <td>-3.052141e+11</td>\n",
       "      <td>0.095183</td>\n",
       "      <td>0.573617</td>\n",
       "      <td>0.016595</td>\n",
       "      <td>1.516520e+11</td>\n",
       "      <td>0.020113</td>\n",
       "      <td>3.647306e+10</td>\n",
       "      <td>0.004254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.214104</td>\n",
       "      <td>0.084924</td>\n",
       "      <td>-2.255775e+11</td>\n",
       "      <td>0.329557</td>\n",
       "      <td>-1.824095e+11</td>\n",
       "      <td>0.450074</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.966261e+11</td>\n",
       "      <td>0.377069</td>\n",
       "      <td>-1.833116e+11</td>\n",
       "      <td>0.456567</td>\n",
       "      <td>0.159613</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>1.165510e+11</td>\n",
       "      <td>0.038107</td>\n",
       "      <td>1.641211e+10</td>\n",
       "      <td>0.018645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.327337</td>\n",
       "      <td>0.038176</td>\n",
       "      <td>-3.022156e+11</td>\n",
       "      <td>0.100709</td>\n",
       "      <td>-2.983433e+11</td>\n",
       "      <td>0.104539</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.856091e+11</td>\n",
       "      <td>0.095162</td>\n",
       "      <td>-3.024819e+11</td>\n",
       "      <td>0.103283</td>\n",
       "      <td>0.034647</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.497293e+11</td>\n",
       "      <td>0.018485</td>\n",
       "      <td>3.639280e+10</td>\n",
       "      <td>0.005366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.000411</td>\n",
       "      <td>0.050103</td>\n",
       "      <td>-3.174452e+11</td>\n",
       "      <td>0.052303</td>\n",
       "      <td>-3.150516e+11</td>\n",
       "      <td>0.054041</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.001650e+11</td>\n",
       "      <td>0.049047</td>\n",
       "      <td>-3.193468e+11</td>\n",
       "      <td>0.053286</td>\n",
       "      <td>0.100703</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>1.546592e+11</td>\n",
       "      <td>0.012793</td>\n",
       "      <td>3.758832e+10</td>\n",
       "      <td>0.002188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.833160</td>\n",
       "      <td>0.072344</td>\n",
       "      <td>-2.874175e+11</td>\n",
       "      <td>0.147905</td>\n",
       "      <td>-2.788030e+11</td>\n",
       "      <td>0.162577</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.663725e+11</td>\n",
       "      <td>0.156105</td>\n",
       "      <td>-2.814553e+11</td>\n",
       "      <td>0.165617</td>\n",
       "      <td>0.017589</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>1.460553e+11</td>\n",
       "      <td>0.025273</td>\n",
       "      <td>3.257637e+10</td>\n",
       "      <td>0.005412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.458281</td>\n",
       "      <td>0.045529</td>\n",
       "      <td>-3.182973e+11</td>\n",
       "      <td>0.048532</td>\n",
       "      <td>-3.151176e+11</td>\n",
       "      <td>0.053503</td>\n",
       "      <td>0.02</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.014448e+11</td>\n",
       "      <td>0.044993</td>\n",
       "      <td>-3.214930e+11</td>\n",
       "      <td>0.046924</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>1.538688e+11</td>\n",
       "      <td>0.010438</td>\n",
       "      <td>3.668054e+10</td>\n",
       "      <td>0.005560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.610744</td>\n",
       "      <td>0.055608</td>\n",
       "      <td>-3.000673e+11</td>\n",
       "      <td>0.108026</td>\n",
       "      <td>-2.954525e+11</td>\n",
       "      <td>0.113172</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.825196e+11</td>\n",
       "      <td>0.104949</td>\n",
       "      <td>-2.991967e+11</td>\n",
       "      <td>0.113022</td>\n",
       "      <td>0.017116</td>\n",
       "      <td>0.004377</td>\n",
       "      <td>1.496624e+11</td>\n",
       "      <td>0.020336</td>\n",
       "      <td>3.596162e+10</td>\n",
       "      <td>0.004762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.308811</td>\n",
       "      <td>0.086558</td>\n",
       "      <td>-3.008764e+11</td>\n",
       "      <td>0.105876</td>\n",
       "      <td>-2.969476e+11</td>\n",
       "      <td>0.108978</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.850065e+11</td>\n",
       "      <td>0.097071</td>\n",
       "      <td>-3.013272e+11</td>\n",
       "      <td>0.106706</td>\n",
       "      <td>5.285480</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>1.498062e+11</td>\n",
       "      <td>0.021792</td>\n",
       "      <td>3.679774e+10</td>\n",
       "      <td>0.007461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.018076</td>\n",
       "      <td>0.072473</td>\n",
       "      <td>-2.648524e+11</td>\n",
       "      <td>0.198386</td>\n",
       "      <td>-2.408697e+11</td>\n",
       "      <td>0.273995</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.300183e+11</td>\n",
       "      <td>0.271279</td>\n",
       "      <td>-2.473128e+11</td>\n",
       "      <td>0.266833</td>\n",
       "      <td>1.928668</td>\n",
       "      <td>0.025667</td>\n",
       "      <td>1.246738e+11</td>\n",
       "      <td>0.043963</td>\n",
       "      <td>2.199194e+10</td>\n",
       "      <td>0.023084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.338188</td>\n",
       "      <td>0.055749</td>\n",
       "      <td>-3.129166e+11</td>\n",
       "      <td>0.064964</td>\n",
       "      <td>-3.101029e+11</td>\n",
       "      <td>0.069242</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.948303e+11</td>\n",
       "      <td>0.065948</td>\n",
       "      <td>-3.132201e+11</td>\n",
       "      <td>0.071449</td>\n",
       "      <td>0.158761</td>\n",
       "      <td>0.002594</td>\n",
       "      <td>1.518546e+11</td>\n",
       "      <td>0.010571</td>\n",
       "      <td>3.787072e+10</td>\n",
       "      <td>0.004848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10.501161</td>\n",
       "      <td>0.094700</td>\n",
       "      <td>-2.815610e+11</td>\n",
       "      <td>0.164997</td>\n",
       "      <td>-2.722391e+11</td>\n",
       "      <td>0.183285</td>\n",
       "      <td>0.02</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.648714e+11</td>\n",
       "      <td>0.160861</td>\n",
       "      <td>-2.756420e+11</td>\n",
       "      <td>0.182850</td>\n",
       "      <td>0.332399</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>1.422797e+11</td>\n",
       "      <td>0.024298</td>\n",
       "      <td>3.421403e+10</td>\n",
       "      <td>0.008917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.034758</td>\n",
       "      <td>0.140172</td>\n",
       "      <td>-2.670271e+11</td>\n",
       "      <td>0.208533</td>\n",
       "      <td>-2.464509e+11</td>\n",
       "      <td>0.259382</td>\n",
       "      <td>0.05</td>\n",
       "      <td>8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.449767e+11</td>\n",
       "      <td>0.223889</td>\n",
       "      <td>-2.548366e+11</td>\n",
       "      <td>0.244529</td>\n",
       "      <td>0.071680</td>\n",
       "      <td>0.070399</td>\n",
       "      <td>1.368912e+11</td>\n",
       "      <td>0.029764</td>\n",
       "      <td>2.794612e+10</td>\n",
       "      <td>0.009192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.780979</td>\n",
       "      <td>0.134963</td>\n",
       "      <td>-2.484368e+11</td>\n",
       "      <td>0.260594</td>\n",
       "      <td>-2.136212e+11</td>\n",
       "      <td>0.357046</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.216550e+11</td>\n",
       "      <td>0.297775</td>\n",
       "      <td>-2.220015e+11</td>\n",
       "      <td>0.341870</td>\n",
       "      <td>0.860330</td>\n",
       "      <td>0.030637</td>\n",
       "      <td>1.252272e+11</td>\n",
       "      <td>0.029261</td>\n",
       "      <td>2.175918e+10</td>\n",
       "      <td>0.015253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.618504</td>\n",
       "      <td>0.068621</td>\n",
       "      <td>-2.720135e+11</td>\n",
       "      <td>0.184894</td>\n",
       "      <td>-2.528237e+11</td>\n",
       "      <td>0.237995</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.435622e+11</td>\n",
       "      <td>0.228371</td>\n",
       "      <td>-2.624755e+11</td>\n",
       "      <td>0.221883</td>\n",
       "      <td>0.077049</td>\n",
       "      <td>0.003164</td>\n",
       "      <td>1.331610e+11</td>\n",
       "      <td>0.026794</td>\n",
       "      <td>2.322875e+10</td>\n",
       "      <td>0.025064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.762832</td>\n",
       "      <td>0.098699</td>\n",
       "      <td>-2.884486e+11</td>\n",
       "      <td>0.146938</td>\n",
       "      <td>-2.816763e+11</td>\n",
       "      <td>0.154846</td>\n",
       "      <td>0.02</td>\n",
       "      <td>8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.709739e+11</td>\n",
       "      <td>0.141527</td>\n",
       "      <td>-2.859355e+11</td>\n",
       "      <td>0.152335</td>\n",
       "      <td>0.768862</td>\n",
       "      <td>0.008415</td>\n",
       "      <td>1.472521e+11</td>\n",
       "      <td>0.030131</td>\n",
       "      <td>3.503128e+10</td>\n",
       "      <td>0.007589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.882711</td>\n",
       "      <td>0.078352</td>\n",
       "      <td>-3.166125e+11</td>\n",
       "      <td>0.053891</td>\n",
       "      <td>-3.138491e+11</td>\n",
       "      <td>0.057357</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.985359e+11</td>\n",
       "      <td>0.054208</td>\n",
       "      <td>-3.189993e+11</td>\n",
       "      <td>0.054316</td>\n",
       "      <td>0.021534</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>1.537393e+11</td>\n",
       "      <td>0.010666</td>\n",
       "      <td>3.668239e+10</td>\n",
       "      <td>0.003042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6.786129</td>\n",
       "      <td>0.086996</td>\n",
       "      <td>-3.078161e+11</td>\n",
       "      <td>0.082882</td>\n",
       "      <td>-3.051320e+11</td>\n",
       "      <td>0.084106</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.910943e+11</td>\n",
       "      <td>0.077784</td>\n",
       "      <td>-3.094029e+11</td>\n",
       "      <td>0.082765</td>\n",
       "      <td>2.396859</td>\n",
       "      <td>0.025529</td>\n",
       "      <td>1.515018e+11</td>\n",
       "      <td>0.016294</td>\n",
       "      <td>3.708053e+10</td>\n",
       "      <td>0.004532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>17.067967</td>\n",
       "      <td>0.146602</td>\n",
       "      <td>-2.346413e+11</td>\n",
       "      <td>0.307575</td>\n",
       "      <td>-2.014217e+11</td>\n",
       "      <td>0.394656</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.106590e+11</td>\n",
       "      <td>0.332611</td>\n",
       "      <td>-2.041242e+11</td>\n",
       "      <td>0.394867</td>\n",
       "      <td>4.232286</td>\n",
       "      <td>0.042468</td>\n",
       "      <td>1.239521e+11</td>\n",
       "      <td>0.035429</td>\n",
       "      <td>2.278005e+10</td>\n",
       "      <td>0.007607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.877657</td>\n",
       "      <td>0.070036</td>\n",
       "      <td>-3.106855e+11</td>\n",
       "      <td>0.074123</td>\n",
       "      <td>-3.083827e+11</td>\n",
       "      <td>0.074461</td>\n",
       "      <td>0.02</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.940624e+11</td>\n",
       "      <td>0.068381</td>\n",
       "      <td>-3.126188e+11</td>\n",
       "      <td>0.073231</td>\n",
       "      <td>1.252153</td>\n",
       "      <td>0.025888</td>\n",
       "      <td>1.526139e+11</td>\n",
       "      <td>0.016199</td>\n",
       "      <td>3.775182e+10</td>\n",
       "      <td>0.005412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.305706</td>\n",
       "      <td>0.191636</td>\n",
       "      <td>-2.362978e+11</td>\n",
       "      <td>0.291576</td>\n",
       "      <td>-1.933895e+11</td>\n",
       "      <td>0.417528</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.980785e+11</td>\n",
       "      <td>0.372467</td>\n",
       "      <td>-1.961905e+11</td>\n",
       "      <td>0.418387</td>\n",
       "      <td>0.652946</td>\n",
       "      <td>0.005302</td>\n",
       "      <td>1.173177e+11</td>\n",
       "      <td>0.043708</td>\n",
       "      <td>1.877229e+10</td>\n",
       "      <td>0.015584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>15.673158</td>\n",
       "      <td>0.226945</td>\n",
       "      <td>-2.569109e+11</td>\n",
       "      <td>0.238871</td>\n",
       "      <td>-2.275817e+11</td>\n",
       "      <td>0.315007</td>\n",
       "      <td>0.02</td>\n",
       "      <td>8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.323955e+11</td>\n",
       "      <td>0.263748</td>\n",
       "      <td>-2.348404e+11</td>\n",
       "      <td>0.303808</td>\n",
       "      <td>0.286972</td>\n",
       "      <td>0.011133</td>\n",
       "      <td>1.326922e+11</td>\n",
       "      <td>0.031362</td>\n",
       "      <td>2.311518e+10</td>\n",
       "      <td>0.014697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.051538</td>\n",
       "      <td>0.101191</td>\n",
       "      <td>-3.074431e+11</td>\n",
       "      <td>0.083802</td>\n",
       "      <td>-3.039051e+11</td>\n",
       "      <td>0.087852</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.888700e+11</td>\n",
       "      <td>0.084831</td>\n",
       "      <td>-3.075714e+11</td>\n",
       "      <td>0.088195</td>\n",
       "      <td>0.026030</td>\n",
       "      <td>0.003740</td>\n",
       "      <td>1.509492e+11</td>\n",
       "      <td>0.016394</td>\n",
       "      <td>3.706372e+10</td>\n",
       "      <td>0.006272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.279572</td>\n",
       "      <td>0.088950</td>\n",
       "      <td>-3.047809e+11</td>\n",
       "      <td>0.093171</td>\n",
       "      <td>-3.015556e+11</td>\n",
       "      <td>0.094570</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.863082e+11</td>\n",
       "      <td>0.092947</td>\n",
       "      <td>-3.060871e+11</td>\n",
       "      <td>0.092595</td>\n",
       "      <td>0.018306</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>1.515993e+11</td>\n",
       "      <td>0.018833</td>\n",
       "      <td>3.599759e+10</td>\n",
       "      <td>0.001855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.604775</td>\n",
       "      <td>0.162989</td>\n",
       "      <td>-2.870165e+11</td>\n",
       "      <td>0.147875</td>\n",
       "      <td>-2.788583e+11</td>\n",
       "      <td>0.162944</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.682612e+11</td>\n",
       "      <td>0.150122</td>\n",
       "      <td>-2.829944e+11</td>\n",
       "      <td>0.161054</td>\n",
       "      <td>0.026930</td>\n",
       "      <td>0.006920</td>\n",
       "      <td>1.445681e+11</td>\n",
       "      <td>0.022393</td>\n",
       "      <td>3.386153e+10</td>\n",
       "      <td>0.004010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.325070</td>\n",
       "      <td>0.111501</td>\n",
       "      <td>-3.032796e+11</td>\n",
       "      <td>0.091657</td>\n",
       "      <td>-2.964018e+11</td>\n",
       "      <td>0.108894</td>\n",
       "      <td>0.02</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.818580e+11</td>\n",
       "      <td>0.107045</td>\n",
       "      <td>-3.029383e+11</td>\n",
       "      <td>0.101930</td>\n",
       "      <td>0.021802</td>\n",
       "      <td>0.003017</td>\n",
       "      <td>1.465660e+11</td>\n",
       "      <td>0.011062</td>\n",
       "      <td>3.248360e+10</td>\n",
       "      <td>0.010108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_mse  mean_test_r2  \\\n",
       "0        3.677182         0.133705  -3.092229e+11      0.074522   \n",
       "1       41.970156         0.201472  -2.583374e+11      0.231846   \n",
       "2        5.496951         0.127762  -2.715555e+11      0.197096   \n",
       "3        1.678362         0.135600  -3.001876e+11      0.107518   \n",
       "4       18.633569         0.155022  -2.873511e+11      0.147606   \n",
       "5        1.694261         0.099786  -3.048876e+11      0.093417   \n",
       "6       11.214104         0.084924  -2.255775e+11      0.329557   \n",
       "7        1.327337         0.038176  -3.022156e+11      0.100709   \n",
       "8        5.000411         0.050103  -3.174452e+11      0.052303   \n",
       "9        0.833160         0.072344  -2.874175e+11      0.147905   \n",
       "10       0.458281         0.045529  -3.182973e+11      0.048532   \n",
       "11       0.610744         0.055608  -3.000673e+11      0.108026   \n",
       "12      12.308811         0.086558  -3.008764e+11      0.105876   \n",
       "13       5.018076         0.072473  -2.648524e+11      0.198386   \n",
       "14       4.338188         0.055749  -3.129166e+11      0.064964   \n",
       "15      10.501161         0.094700  -2.815610e+11      0.164997   \n",
       "16       2.034758         0.140172  -2.670271e+11      0.208533   \n",
       "17       2.780979         0.134963  -2.484368e+11      0.260594   \n",
       "18       1.618504         0.068621  -2.720135e+11      0.184894   \n",
       "19       4.762832         0.098699  -2.884486e+11      0.146938   \n",
       "20       0.882711         0.078352  -3.166125e+11      0.053891   \n",
       "21       6.786129         0.086996  -3.078161e+11      0.082882   \n",
       "22      17.067967         0.146602  -2.346413e+11      0.307575   \n",
       "23       3.877657         0.070036  -3.106855e+11      0.074123   \n",
       "24       4.305706         0.191636  -2.362978e+11      0.291576   \n",
       "25      15.673158         0.226945  -2.569109e+11      0.238871   \n",
       "26       1.051538         0.101191  -3.074431e+11      0.083802   \n",
       "27       1.279572         0.088950  -3.047809e+11      0.093171   \n",
       "28       2.604775         0.162989  -2.870165e+11      0.147875   \n",
       "29       2.325070         0.111501  -3.032796e+11      0.091657   \n",
       "\n",
       "    mean_train_mse  mean_train_r2 param_learning_rate param_max_depth  \\\n",
       "0    -3.037309e+11       0.087037                0.01               4   \n",
       "1    -2.278631e+11       0.315189                0.02               8   \n",
       "2    -2.555767e+11       0.232927                0.05               8   \n",
       "3    -2.961826e+11       0.110913                0.05               4   \n",
       "4    -2.799286e+11       0.160181                0.02               6   \n",
       "5    -3.018425e+11       0.093892                0.02               6   \n",
       "6    -1.824095e+11       0.450074                 0.1               8   \n",
       "7    -2.983433e+11       0.104539                0.05               4   \n",
       "8    -3.150516e+11       0.054041                0.01               8   \n",
       "9    -2.788030e+11       0.162577                 0.1               4   \n",
       "10   -3.151176e+11       0.053503                0.02               6   \n",
       "11   -2.954525e+11       0.113172                0.05               6   \n",
       "12   -2.969476e+11       0.108978                0.01               6   \n",
       "13   -2.408697e+11       0.273995                0.05               4   \n",
       "14   -3.101029e+11       0.069242                0.01               6   \n",
       "15   -2.722391e+11       0.183285                0.02               6   \n",
       "16   -2.464509e+11       0.259382                0.05               8   \n",
       "17   -2.136212e+11       0.357046                 0.1               8   \n",
       "18   -2.528237e+11       0.237995                0.05               4   \n",
       "19   -2.816763e+11       0.154846                0.02               8   \n",
       "20   -3.138491e+11       0.057357                0.01               4   \n",
       "21   -3.051320e+11       0.084106                0.01               4   \n",
       "22   -2.014217e+11       0.394656                 0.1               8   \n",
       "23   -3.083827e+11       0.074461                0.02               6   \n",
       "24   -1.933895e+11       0.417528                 0.1               8   \n",
       "25   -2.275817e+11       0.315007                0.02               8   \n",
       "26   -3.039051e+11       0.087852                0.05               6   \n",
       "27   -3.015556e+11       0.094570                0.05               4   \n",
       "28   -2.788583e+11       0.162944                0.05               6   \n",
       "29   -2.964018e+11       0.108894                0.02               4   \n",
       "\n",
       "   param_max_features param_min_samples_leaf      ...      split4_test_mse  \\\n",
       "0                 0.3                     20      ...        -2.889174e+11   \n",
       "1                   1                     20      ...        -2.359228e+11   \n",
       "2                 0.3                     50      ...        -2.510849e+11   \n",
       "3                 0.1                    100      ...        -2.830079e+11   \n",
       "4                   1                    100      ...        -2.707783e+11   \n",
       "5                 0.1                    150      ...        -2.863462e+11   \n",
       "6                   1                     50      ...        -1.966261e+11   \n",
       "7                   1                    150      ...        -2.856091e+11   \n",
       "8                   1                    100      ...        -3.001650e+11   \n",
       "9                 0.1                    100      ...        -2.663725e+11   \n",
       "10                0.1                     20      ...        -3.014448e+11   \n",
       "11                0.1                    100      ...        -2.825196e+11   \n",
       "12                  1                    150      ...        -2.850065e+11   \n",
       "13                  1                     20      ...        -2.300183e+11   \n",
       "14                  1                     50      ...        -2.948303e+11   \n",
       "15                  1                    100      ...        -2.648714e+11   \n",
       "16                0.1                     50      ...        -2.449767e+11   \n",
       "17                0.1                     50      ...        -2.216550e+11   \n",
       "18                0.3                     20      ...        -2.435622e+11   \n",
       "19                0.3                    150      ...        -2.709739e+11   \n",
       "20                0.1                     20      ...        -2.985359e+11   \n",
       "21                  1                    150      ...        -2.910943e+11   \n",
       "22                  1                    100      ...        -2.106590e+11   \n",
       "23                  1                    150      ...        -2.940624e+11   \n",
       "24                0.1                     20      ...        -1.980785e+11   \n",
       "25                0.3                     20      ...        -2.323955e+11   \n",
       "26                0.1                    100      ...        -2.888700e+11   \n",
       "27                0.3                    100      ...        -2.863082e+11   \n",
       "28                0.1                    100      ...        -2.682612e+11   \n",
       "29                0.3                     20      ...        -2.818580e+11   \n",
       "\n",
       "   split4_test_r2  split4_train_mse  split4_train_r2  std_fit_time  \\\n",
       "0        0.084681     -3.105650e+11         0.079320      0.275039   \n",
       "1        0.252573     -2.300173e+11         0.318106      0.817238   \n",
       "2        0.204538     -2.586266e+11         0.233293      0.148698   \n",
       "3        0.103403     -3.012389e+11         0.106968      0.075116   \n",
       "4        0.142147     -2.831700e+11         0.160534      0.483051   \n",
       "5        0.092826     -3.052141e+11         0.095183      0.573617   \n",
       "6        0.377069     -1.833116e+11         0.456567      0.159613   \n",
       "7        0.095162     -3.024819e+11         0.103283      0.034647   \n",
       "8        0.049047     -3.193468e+11         0.053286      0.100703   \n",
       "9        0.156105     -2.814553e+11         0.165617      0.017589   \n",
       "10       0.044993     -3.214930e+11         0.046924      0.008264   \n",
       "11       0.104949     -2.991967e+11         0.113022      0.017116   \n",
       "12       0.097071     -3.013272e+11         0.106706      5.285480   \n",
       "13       0.271279     -2.473128e+11         0.266833      1.928668   \n",
       "14       0.065948     -3.132201e+11         0.071449      0.158761   \n",
       "15       0.160861     -2.756420e+11         0.182850      0.332399   \n",
       "16       0.223889     -2.548366e+11         0.244529      0.071680   \n",
       "17       0.297775     -2.220015e+11         0.341870      0.860330   \n",
       "18       0.228371     -2.624755e+11         0.221883      0.077049   \n",
       "19       0.141527     -2.859355e+11         0.152335      0.768862   \n",
       "20       0.054208     -3.189993e+11         0.054316      0.021534   \n",
       "21       0.077784     -3.094029e+11         0.082765      2.396859   \n",
       "22       0.332611     -2.041242e+11         0.394867      4.232286   \n",
       "23       0.068381     -3.126188e+11         0.073231      1.252153   \n",
       "24       0.372467     -1.961905e+11         0.418387      0.652946   \n",
       "25       0.263748     -2.348404e+11         0.303808      0.286972   \n",
       "26       0.084831     -3.075714e+11         0.088195      0.026030   \n",
       "27       0.092947     -3.060871e+11         0.092595      0.018306   \n",
       "28       0.150122     -2.829944e+11         0.161054      0.026930   \n",
       "29       0.107045     -3.029383e+11         0.101930      0.021802   \n",
       "\n",
       "    std_score_time  std_test_mse  std_test_r2  std_train_mse  std_train_r2  \n",
       "0         0.006721  1.496828e+11     0.009902   3.373494e+10      0.008631  \n",
       "1         0.004731  1.310998e+11     0.028790   2.583633e+10      0.008343  \n",
       "2         0.003568  1.395634e+11     0.029904   3.121153e+10      0.007312  \n",
       "3         0.010641  1.497048e+11     0.020035   3.590904e+10      0.004921  \n",
       "4         0.003959  1.448758e+11     0.023719   3.511027e+10      0.008894  \n",
       "5         0.016595  1.516520e+11     0.020113   3.647306e+10      0.004254  \n",
       "6         0.002068  1.165510e+11     0.038107   1.641211e+10      0.018645  \n",
       "7         0.001200  1.497293e+11     0.018485   3.639280e+10      0.005366  \n",
       "8         0.002514  1.546592e+11     0.012793   3.758832e+10      0.002188  \n",
       "9         0.002686  1.460553e+11     0.025273   3.257637e+10      0.005412  \n",
       "10        0.002246  1.538688e+11     0.010438   3.668054e+10      0.005560  \n",
       "11        0.004377  1.496624e+11     0.020336   3.596162e+10      0.004762  \n",
       "12        0.002417  1.498062e+11     0.021792   3.679774e+10      0.007461  \n",
       "13        0.025667  1.246738e+11     0.043963   2.199194e+10      0.023084  \n",
       "14        0.002594  1.518546e+11     0.010571   3.787072e+10      0.004848  \n",
       "15        0.003011  1.422797e+11     0.024298   3.421403e+10      0.008917  \n",
       "16        0.070399  1.368912e+11     0.029764   2.794612e+10      0.009192  \n",
       "17        0.030637  1.252272e+11     0.029261   2.175918e+10      0.015253  \n",
       "18        0.003164  1.331610e+11     0.026794   2.322875e+10      0.025064  \n",
       "19        0.008415  1.472521e+11     0.030131   3.503128e+10      0.007589  \n",
       "20        0.002591  1.537393e+11     0.010666   3.668239e+10      0.003042  \n",
       "21        0.025529  1.515018e+11     0.016294   3.708053e+10      0.004532  \n",
       "22        0.042468  1.239521e+11     0.035429   2.278005e+10      0.007607  \n",
       "23        0.025888  1.526139e+11     0.016199   3.775182e+10      0.005412  \n",
       "24        0.005302  1.173177e+11     0.043708   1.877229e+10      0.015584  \n",
       "25        0.011133  1.326922e+11     0.031362   2.311518e+10      0.014697  \n",
       "26        0.003740  1.509492e+11     0.016394   3.706372e+10      0.006272  \n",
       "27        0.003322  1.515993e+11     0.018833   3.599759e+10      0.001855  \n",
       "28        0.006920  1.445681e+11     0.022393   3.386153e+10      0.004010  \n",
       "29        0.003017  1.465660e+11     0.011062   3.248360e+10      0.010108  \n",
       "\n",
       "[30 rows x 40 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
